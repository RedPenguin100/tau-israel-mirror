{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# conda activate aso_design\n",
    "import pandas as pd\n",
    "from scripts.data_genertion.consts import *\n",
    "from asodesigner.file_utils import read_human_genome_fasta_dict\n",
    "from asodesigner.consts import *\n",
    "import numpy as np\n",
    "from asodesigner.util import get_antisense\n",
    "import pickle\n",
    "from read_human_genome import get_locus_to_data_dict\n",
    "from file_utils import read_human_genome_fasta_dict\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "csv_path = os.path.join(project_root, 'scripts', 'data_genertion', 'data_asoptimizer_updated.csv')\n",
    "all_data = pd.read_csv(csv_path)"
   ],
   "id": "cc525aee743603bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Column name definitions from the ASO experiment dataset.\n",
    "SEQUENCE = 'Sequence'\n",
    "INHIBITION = 'Inhibition(%)'\n",
    "CANONICAL_GENE = 'Canonical Gene Name'\n",
    "CELL_LINE_ORGANISM = 'Cell line organism'\n",
    "VOLUME = 'ASO_volume(nM)'\n",
    "TREATMENT_PERIOD = 'Treatment_Period(hours)'\n",
    "CELL_LINE = 'Cell_line'\n",
    "TRANSFECTION = 'Transfection'\n",
    "DENSITY = 'Density(cells/well)'\n",
    "MODIFICATION = 'Modification'"
   ],
   "id": "4dc38f8e59845fe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocessing ASO Experimental Dataset",
   "id": "71907df835d9eac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_data_no_nan = all_data.dropna(subset=[INHIBITION]).copy()\n",
    "all_data_no_nan.loc[:, 'log_inhibition'] = -np.log(-all_data_no_nan[INHIBITION] + 100.001)"
   ],
   "id": "a741380ef13e8209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_data_no_nan_human = all_data_no_nan[all_data_no_nan[CELL_LINE_ORGANISM] == 'human']\n",
    "genes = all_data_no_nan[CANONICAL_GENE].copy()\n",
    "genes_u = list(set(genes))\n",
    "genes_u.remove('HBV')\n",
    "genes_u.remove('negative_control')"
   ],
   "id": "9a46084d368aaabc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load gene information from cache or generate it if needed\n",
    "cache_path = CACHE_DIR / 'gene_to_data_simple_cache.pickle'\n",
    "if not cache_path.exists():\n",
    "    gene_to_data = get_locus_to_data_dict(include_introns=True, gene_subset=genes_u)\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump(gene_to_data, f)\n",
    "else:\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        gene_to_data = pickle.load(f)\n"
   ],
   "id": "93b8403c09b4dd6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter data to keep only rows with valid gene information\n",
    "all_data_human_gene = all_data_no_nan_human[all_data_no_nan_human[CANONICAL_GENE].isin(genes_u)].copy()\n",
    "\n",
    "# Define names for new columns\n",
    "SENSE_SEQUENCE = 'sense_sequence'\n",
    "PRE_MRNA_SEQUENCE = 'pre_mrna_sequence'\n",
    "SENSE_START = 'sense_start'\n",
    "SENSE_LENGTH = 'sense_length'\n",
    "\n",
    "# Initialize new columns\n",
    "all_data_human_gene[SENSE_SEQUENCE] = \"\"\n",
    "all_data_human_gene[PRE_MRNA_SEQUENCE] = \"\"\n",
    "all_data_human_gene[SENSE_START] = np.zeros_like(all_data_human_gene[CANONICAL_GENE], dtype=int)\n",
    "all_data_human_gene[SENSE_LENGTH] = np.zeros_like(all_data_human_gene[CANONICAL_GENE], dtype=int)\n",
    "\n",
    "# Iterate over each row and compute the antisense complement and the gene's pre-mRNA\n",
    "for index, row in all_data_human_gene.iterrows():\n",
    "    gene_name = row[CANONICAL_GENE]\n",
    "\n",
    "    if gene_name not in gene_to_data:\n",
    "        continue  # Skip genes not found in genome annotation\n",
    "\n",
    "    locus_info = gene_to_data[gene_name]\n",
    "    pre_mrna = locus_info.full_mrna\n",
    "    antisense = row[SEQUENCE]\n",
    "    sense = get_antisense(antisense)\n",
    "    idx = pre_mrna.find(sense)\n",
    "\n",
    "    # Store computed sequences in new columns\n",
    "    all_data_human_gene.loc[index, SENSE_START] = idx\n",
    "    all_data_human_gene.loc[index, SENSE_LENGTH] = len(antisense)\n",
    "    all_data_human_gene.at[index, SENSE_SEQUENCE] = sense\n",
    "    all_data_human_gene.at[index, PRE_MRNA_SEQUENCE] = pre_mrna"
   ],
   "id": "17712b5ce15f2c9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data_human_gene.head()",
   "id": "aef54e69eb290bc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adding Flanked Sense Sequences to Dataset",
   "id": "a74afd873238e690"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_sense_with_flanks(pre_mrna: str, sense_start: int, sense_length: int, flank_size: int) -> str:\n",
    "    \"\"\"\n",
    "    Re  turns the sense sequence with `flank_size` nucleotides on each side (if available).\n",
    "    If near the edge, it will not go out of bounds.\n",
    "\n",
    "    Parameters:\n",
    "    - pre_mrna: The full pre-mRNA sequence (5' -> 3')\n",
    "    - sense_start: Start index of the sense sequence within pre_mrna\n",
    "    - sense_length: Length of the sense sequence (usually same as antisense length)\n",
    "    - flank_size: Number of nucleotides to include on each side (upstream and downstream)\n",
    "\n",
    "    Returns:\n",
    "    - str: The flanked sense sequence\n",
    "    \"\"\"\n",
    "    # Ensure indices are within bounds\n",
    "    start = max(0, sense_start - flank_size)\n",
    "    end = min(len(pre_mrna), sense_start + sense_length + flank_size)\n",
    "\n",
    "    return pre_mrna[start:end]\n"
   ],
   "id": "342927a38d3843c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FLANK_SIZE = 120  # Change this as needed\n",
    "FLANKED_SENSE_COL = f'sense_with_flank_{FLANK_SIZE}nt'\n",
    "\n",
    "# Create new column with flanked sequences\n",
    "all_data_human_gene[FLANKED_SENSE_COL] = all_data_human_gene.apply(\n",
    "    lambda row: get_sense_with_flanks(\n",
    "        row['pre_mrna_sequence'],\n",
    "        row['sense_start'],\n",
    "        row['sense_length'],\n",
    "        flank_size=FLANK_SIZE\n",
    "    ) if row['sense_start'] != -1 else \"\",  # Handle cases where sense was not found\n",
    "    axis=1\n",
    ")\n"
   ],
   "id": "fb305565ced66d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_data_human_gene.head()",
   "id": "7f62e821850a293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Running RNAaccess on the sense with flanks",
   "id": "832e3362a9f3c804"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from yehuda_code.access_calculator import AccessCalculator\n",
    "def compute_sense_accessibility(row, flank_size, access_win_size, seed_sizes, access_size, min_gc=0, max_gc=100, gc_ranges=1):\n",
    "    try:\n",
    "        # Skip invalid rows\n",
    "        if row['sense_start'] == -1 or pd.isna(row['sense_with_flank_120nt']) or row['sense_with_flank_120nt'] == \"\":\n",
    "            return None\n",
    "\n",
    "        seq = row[f'sense_with_flank_{flank_size}nt']\n",
    "        sense_start = row['sense_start']\n",
    "        sense_length = row['sense_length']\n",
    "\n",
    "        # Calculate accessibility\n",
    "        df_access = AccessCalculator.calc(\n",
    "            seq, access_size,\n",
    "            min_gc, max_gc, gc_ranges,\n",
    "            access_win_size, seed_sizes\n",
    "        )\n",
    "\n",
    "        flank_start = max(0, sense_start - flank_size)\n",
    "        sense_start_in_flank = sense_start - flank_start\n",
    "        sense_end_in_flank = sense_start_in_flank + sense_length\n",
    "\n",
    "        if 0 <= sense_start_in_flank < len(df_access) and sense_end_in_flank <= len(df_access):\n",
    "            values = df_access['avg_access'].iloc[sense_start_in_flank:sense_end_in_flank].dropna()\n",
    "            return values.mean() if not values.empty else None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row.name} | seq start: {row['sense_start']} | error: {e}\")\n",
    "        return None\n"
   ],
   "id": "71fd11f1d8f2e9f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_batch_accessibility(df, flank_size, access_win_size, seed_sizes, access_size,\n",
    "                                min_gc=0, max_gc=100, gc_ranges=1):\n",
    "    # list of the results\n",
    "    results = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            if row['sense_start'] == -1 or pd.isna(row[f'sense_with_flank_{flank_size}nt']) or row[f'sense_with_flank_{flank_size}nt'] == \"\":\n",
    "                results.append(None)\n",
    "                continue\n",
    "\n",
    "            seq = row[f'sense_with_flank_{flank_size}nt']\n",
    "            sense_start = row['sense_start']\n",
    "            sense_length = row['sense_length']\n",
    "\n",
    "            # access calculation for each sense\n",
    "            df_access = AccessCalculator.calc(\n",
    "                seq, access_size,\n",
    "                min_gc, max_gc, gc_ranges,\n",
    "                access_win_size, seed_sizes\n",
    "            )\n",
    "\n",
    "            flank_start = max(0, sense_start - flank_size)\n",
    "            sense_start_in_flank = sense_start - flank_start\n",
    "            sense_end_in_flank = sense_start_in_flank + sense_length\n",
    "\n",
    "            if 0 <= sense_start_in_flank < len(df_access) and sense_end_in_flank <= len(df_access):\n",
    "                values = df_access['avg_access'].iloc[sense_start_in_flank:sense_end_in_flank].dropna()\n",
    "                results.append(values.mean() if not values.empty else None)\n",
    "            else:\n",
    "                results.append(None)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at row {i}: {e}\")\n",
    "            results.append(None)\n",
    "\n",
    "    return results\n"
   ],
   "id": "19fd14382291053e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final best parameters\n",
   "id": "83df9d68cbe65c23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Parameters that were tested:\n",
    "\n",
    "- **Access window sizes:**\n",
    "  `[10, 15, 20, 25, 35, 45, 60, 70, 80, 100]`\n",
    "\n",
    "- **Seed sizes:**\n",
    "  `[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]`\n",
    "\n",
    "- **Accessibility sizes (ACCESS_SIZES):**\n",
    "  `[13, 14, 15, 16, 17, 18, 19]`"
   ],
   "id": "daa3972061dadd16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the best access_win_size = 70, checking the seed size 13\n",
   "id": "8353a457a9d02e06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FLANK_SIZE = 120\n",
    "ACCESS_SIZE = 13\n",
    "SEED_SIZE = 13\n",
    "SEED_SIZES = [SEED_SIZE * m for m in range(1, 4)]\n",
    "ACCESS_WIN_SIZE = 80"
   ],
   "id": "4aafd030cd365c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "# Create a unique output folder name with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_folder = f\"partial_batches_{timestamp}\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f\"Output will be saved to: {output_folder}\")\n"
   ],
   "id": "34ec279fe9f6a80d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 500\n",
    "for start_idx in range(0, len(all_data_human_gene), batch_size):\n",
    "    end_idx = min(start_idx + batch_size, len(all_data_human_gene))\n",
    "    batch = all_data_human_gene.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "    print(f\"Processing rows {start_idx} to {end_idx}...\")\n",
    "\n",
    "    batch['sense_avg_accessibility'] = batch.apply(\n",
    "        compute_sense_accessibility,\n",
    "        axis=1,\n",
    "        flank_size=FLANK_SIZE,\n",
    "        access_win_size=ACCESS_WIN_SIZE,\n",
    "        seed_sizes=SEED_SIZES,\n",
    "        access_size=ACCESS_SIZE,\n",
    "    )\n",
    "\n",
    "    # Save batch to the new folder\n",
    "    batch.to_csv(f\"{output_folder}/batch_{start_idx}_{end_idx}.csv\", index=False)\n"
   ],
   "id": "f1f5dbcc03180ce2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Load all batch files from the new output folder\n",
    "files = sorted(glob.glob(f\"{output_folder}/batch_*.csv\"))\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], axis=0)\n",
    "\n",
    "# Save full combined file\n",
    "combined_file = f\"all_data_with_accessibility_{timestamp}.csv\"\n",
    "df_all.to_csv(combined_file, index=False)\n",
    "print(f\"Saved combined CSV to: {combined_file}\")"
   ],
   "id": "cf10787ab283c5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_corr = df_all.dropna(subset=['sense_avg_accessibility', 'log_inhibition'])"
   ],
   "id": "379a85d2412c4dbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_corr.head()",
   "id": "50122255f0777f16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Compute correlations\n",
    "pearson_corr, pearson_p = pearsonr(df_corr['sense_avg_accessibility'], df_corr['log_inhibition'])\n",
    "spearman_corr, spearman_p = spearmanr(df_corr['sense_avg_accessibility'], df_corr['log_inhibition'])\n",
    "\n",
    "print(f\"Pearson correlation: r = {pearson_corr:.4f}, p = {pearson_p:.4e}\")\n",
    "print(f\"Spearman correlation: r = {spearman_corr:.4f}, p = {spearman_p:.4e}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(\n",
    "    x='sense_avg_accessibility',\n",
    "    y='log_inhibition',\n",
    "    data=df_corr,\n",
    "    scatter_kws={'s': 30, 'alpha': 0.6},\n",
    "    line_kws={'color': 'red'}\n",
    ")\n",
    "plt.title(f'Accessibility vs log_inhibition\\nPearson r = {pearson_corr:.2f}, Spearman Ï = {spearman_corr:.2f}')\n",
    "plt.xlabel('Sense Avg Accessibility')\n",
    "plt.ylabel('log_inhibition')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_folder}/correlation_plot.png\", dpi=300)\n",
    "plt.show()\n"
   ],
   "id": "445a09350568700d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts', 'features')))\n",
    "\n",
    "from feature_extraction import save_feature"
   ],
   "id": "895d0a2e1ccc0b7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_feature(df_all, 'sense_avg_accessibility')",
   "id": "54735fb232a5ac25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Keep only the relevant columns\n",
    "df_to_save = df_all[['index', 'sense_avg_accessibility', 'log_inhibition']].copy()\n",
    "\n",
    "# Save to CSV\n",
    "df_to_save.to_csv('average_RNAaccess_win70_seed_13_flank120.csv', index=False)\n",
    "\n",
    "# Optional: Print confirmation\n",
    "print(\"Saved CSV with selected columns to 'average_RNAaccess_win70_seed_13_flank120.csv'\")\n"
   ],
   "id": "51d08b14d1b255aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remember to delete in the end the partial batches and the \"all_data_with_accessibility\" file",
   "id": "c4244c7ee0d5e357"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
