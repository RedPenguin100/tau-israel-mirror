{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d64118f2c22bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:06:47.815133Z",
     "start_time": "2025-09-17T21:06:47.627811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle exist\n",
      "                  Sequence  sense_start  sense_length  sense_start_from_end  \\\n",
      "1894  CATTTTCGTCTGCGTTTAGT         1894            20                  6935   \n",
      "1903  TAATCTTTCCATTTTCGTCT         1903            20                  6926   \n",
      "4275  TTTACTTTTTCCATTCTAAG         4275            20                  4554   \n",
      "2285  CATTTTTTCAGTGCTATTTT         2285            20                  6544   \n",
      "5040  ATAATCTTTTCTGCCTTTAC         5040            20                  3789   \n",
      "2155  TTGTTTCTATCTTCCAATTT         2155            20                  6674   \n",
      "2157  TCTTGTTTCTATCTTCCAAT         2157            20                  6672   \n",
      "1893  ATTTTCGTCTGCGTTTAGTA         1893            20                  6936   \n",
      "2005  TATCTTCTCTATTCTTTTCT         2005            20                  6824   \n",
      "440   TACACTGCTCTGGGTCTGCT          440            20                  8389   \n",
      "2274  TGCTATTTTATCCAATTTTT         2274            20                  6555   \n",
      "2007  CCTATCTTCTCTATTCTTTT         2007            20                  6822   \n",
      "\n",
      "     Canonical Gene Name Cell line organism  Inhibition(%)  sense_exon  \\\n",
      "1894              MALAT1              human              0           1   \n",
      "1903              MALAT1              human              0           1   \n",
      "4275              MALAT1              human              0           1   \n",
      "2285              MALAT1              human              0           1   \n",
      "5040              MALAT1              human              0           1   \n",
      "2155              MALAT1              human              0           1   \n",
      "2157              MALAT1              human              0           1   \n",
      "1893              MALAT1              human              0           1   \n",
      "2005              MALAT1              human              0           1   \n",
      "440               MALAT1              human              0           0   \n",
      "2274              MALAT1              human              0           1   \n",
      "2007              MALAT1              human              0           1   \n",
      "\n",
      "      sense_intron  sense_utr  ... CAI_score_30_CDS  CAI_score_40_CDS  \\\n",
      "1894             0          0  ...         0.867043          0.805865   \n",
      "1903             0          0  ...         0.883451          0.794249   \n",
      "4275             0          0  ...         0.878868          0.859152   \n",
      "2285             0          0  ...         0.849633          0.806974   \n",
      "5040             0          0  ...         0.898867          0.898617   \n",
      "2155             0          0  ...         0.770509          0.866787   \n",
      "2157             0          0  ...         0.867838          0.849723   \n",
      "1893             0          0  ...         0.779770          0.786305   \n",
      "2005             0          0  ...         0.825683          0.778679   \n",
      "440              1          0  ...              NaN               NaN   \n",
      "2274             0          0  ...         0.813551          0.853820   \n",
      "2007             0          0  ...         0.813275          0.835999   \n",
      "\n",
      "      CAI_score_50_CDS  CAI_score_60_CDS  CAI_score_70_CDS  \\\n",
      "1894          0.807928          0.826517          0.798113   \n",
      "1903          0.792173          0.828280          0.797744   \n",
      "4275          0.897340          0.888254          0.864975   \n",
      "2285          0.760972          0.836173          0.803144   \n",
      "5040          0.885259          0.885170          0.898855   \n",
      "2155          0.832059          0.806259          0.842254   \n",
      "2157          0.785638          0.836630          0.831237   \n",
      "1893          0.823107          0.785049          0.790454   \n",
      "2005          0.826597          0.854224          0.812092   \n",
      "440                NaN               NaN               NaN   \n",
      "2274          0.819805          0.787378          0.839771   \n",
      "2007          0.843159          0.799256          0.824982   \n",
      "\n",
      "      CAI_score_global_CDS  sense_avg_accessibility  \\\n",
      "1894              0.853307                      0.5   \n",
      "1903              0.853307                      0.5   \n",
      "4275              0.853307                      0.5   \n",
      "2285              0.853307                      0.5   \n",
      "5040              0.853307                      0.5   \n",
      "2155              0.853307                      0.5   \n",
      "2157              0.853307                      0.5   \n",
      "1893              0.853307                      0.5   \n",
      "2005              0.853307                      0.5   \n",
      "440               0.853307                      0.5   \n",
      "2274              0.853307                      0.5   \n",
      "2007              0.853307                      0.5   \n",
      "\n",
      "      RNaseH1_Krel_score_R7_krel     score                 sense  \n",
      "1894                    0.979906  0.541849  ACTAAACGCAGACGAAAATG  \n",
      "1903                    0.980127  0.525541  AGACGAAAATGGAAAGATTA  \n",
      "4275                    0.986435  0.405301  CTTAGAATGGAAAAAGTAAA  \n",
      "2285                    0.978258  0.403576  AAAATAGCACTGAAAAAATG  \n",
      "5040                    0.976839  0.381361  GTAAAGGCAGAAAAGATTAT  \n",
      "2155                    0.974491  0.375237  AAATTGGAAGATAGAAACAA  \n",
      "2157                    0.988863  0.373018  ATTGGAAGATAGAAACAAGA  \n",
      "1893                    0.985002  0.362930  TACTAAACGCAGACGAAAAT  \n",
      "2005                    0.974312  0.362328  AGAAAAGAATAGAGAAGATA  \n",
      "440                     0.994316  0.358173  AGCAGACCCAGAGCAGTGTA  \n",
      "2274                    0.973764  0.349868  AAAAATTGGATAAAATAGCA  \n",
      "2007                    0.977993  0.344258  AAAAGAATAGAGAAGATAGG  \n",
      "\n",
      "[12 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from run_pipe import get_n_best_res\n",
    "flag = True\n",
    "genes_u = ['HIF1A', 'APOL1', 'YAP1', 'SOD1', 'SNCA', 'IRF4', 'KRAS', 'KLKB1', 'SNHG14', 'DGAT2', 'IRF5', 'HTRA1',\n",
    "           'MYH7', 'MALAT1', 'HSD17B13']\n",
    "\n",
    "tp = 24\n",
    "n=12\n",
    "genes_lst  = ['MALAT1']\n",
    "res = get_n_best_res(genes_lst,n,tp)\n",
    "print(res['MALAT1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04276328-d5fe-4b1a-932b-2083b2ad3a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle exist\n"
     ]
    }
   ],
   "source": [
    "from utils import create_gene_to_data\n",
    "genes_lst  = ['MALAT1']\n",
    "\n",
    "gene_to_data = create_gene_to_data(genes_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3bafb8-5e82-42d4-aa70-7dff9ca26671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocusInfo:\n",
      "  exons: [Seq('GACGCAGCCCCACCGGTTGCGCAGTCCCTCCCCGCCCCCGCTCTCCCCTCCGCA...AAG'), Seq('GTGGTAAACTATACCTACTGTCCCTCAAGAGAACACAAGAAGTGCTTTAAGAG'), Seq('GCGGCGGAAGGTGATCGAATTCCGGTGATGCGAGTTGTTCTCCGTCTATAAATA...CAG'), Seq('GGCAAATATTGGCAATTAGTTGGCAGTGGCCTGTTACGGTTGGGATTGGTGGGG...CAA'), Seq('ACTTTTTTCAGATAACATCTTCTGAGTCATAACCAGCCTGGCAGTATGATGGCC...AAA'), Seq('GGGGATTCTTCTCTAATCTTTCAGAAACTTTGTCTGCGAACACTCTTTAATGGA...AAG'), Seq('TTTCCAAAGTTTGCATGTTAACTTTAAATGCTTACAATCTTAGAGTGGTAGGCA...CTA'), Seq('AGGCATTTCATCCTTCATGAAGCCATTCAGGATTTTGAATTGCATATGAGTGCT...CTA'), Seq('ACTTCACAGAGAATGCAGTTGTCTTGACTTCAG'), Seq('ACTTCACAGAGAATGCAGTTGTCTTGACTTCAGGTCTGTCTGTTCTGTTGGCAA...AAG'), Seq('ATGCAACCTTAAAATCAGTGACAAGAAACATT'), Seq('CGTATGCGAAGGGCCAGAGAAGCCAGACCCAGTAAGAAAAAATAGCCTATTTAC...AAG'), Seq('CACCGAAGGCTTAAAGTAGGACAACCATGGAGCCTTCCTGTGGCAGGAGAGACA...AAG'), Seq('CGAAGGCTTAAAGTAGGACAACCATGGAGCCTTCCTGTGGCAGGAGAGACAACA...AAG'), Seq('CTTTTCCAGAAGCCTGTTAAAAGCAAGGTCTCCCCACAAGCAACTTCTCTGCCA...AAG'), Seq('ACCCTTCACCCCTCACCTCGATGCAGCCAGTAGCTTGGATCCTTGTGGGCATGA...AAG'), Seq('GTGGGAGGTAACAGCACAATATCTTTGAACTATATACATCCTTGATGTATAATT...AAC'), Seq('GTAATAGCCTGCAGCTGGTGTTTTGAGAAGCCCTACTGCTGAAAACTTAACAAT...CTC'), Seq('GTAATAGCCTGCAGCTGGTGTTTTGAGAAGCCCTACTGCTGAAAACTTAACAAT...AAA'), Seq('GTAATAGCCTGCAGCTGGTGTTTTGAGAAGCCCTACTGCTGAAAACTTAACAAT...AAA')]\n",
      "  introns: [Seq('GCAGGTCCCCTCTGACGCCTCCGGGAGCCCAGGTTTCCCAGAGTCCTTGGGACG...AAG'), Seq('GTATTTTAAAAGTTCCGGGGGTTTTGTGAGGTGTTTGATGACCCGTTTAAAATA...AAG'), Seq('GTAAGATTCTATTTTCAGTTGTGTGTAAGCAAGTTTTTTTTTAGTGTAGGAGAA...TAG'), Seq('GCAGGAAAGACAAATTTTATTCTTCATAAAGTGATGAGCATATAATAATTCCAG...CAG'), Seq('GTGGGAGATTATGATCAGAGTAAAAGGTAATTACACATTTTATTTCCAGAAAGT...GAG'), Seq('GTGAGTGTATGAGACCTTGCAGTGAGTTTATCAGCATACTCAAAATTTTTTTCC...CAG'), Seq('GTGAGTGTATGAGACCTTGCAGTGAGTTTATCAGCATACTCAAAATTTTTTTCC...CAG'), Seq('GTCTGTCTGTTCTGTTGGCAAGTAAATGCAGTACTGTTCTGATCCCGCTGCTAT...CAG'), Seq('GTCAAGAGAAGTGTCAGCCTCACCTGATTTTTATTAGTAATGAGGACTTGCCTC...TAG'), Seq('GTCAAGAGAAGTGTCAGCCTCACCTGATTTTTATTAGTAATGAGGACTTGCCTC...CAG'), Seq('GTAACGATGGTGTCGAGGTCTTTGGTGGGTTGAACTATGTTAGAAAAGGCCATT...CAG'), Seq('GTAACGATGGTGTCGAGGTCTTTGGTGGGTTGAACTATGTTAGAAAAGGCCATT...CAG'), Seq('GTAACGATGGTGTCGAGGTCTTTGGTGGGTTGAACTATGTTAGAAAAGGCCATT...CAG')]\n",
      "  exon_indices: [(65497687, 65497865), (65498681, 65498734), (65498968, 65503905), (65501847, 65502393), (65502636, 65503609), (65503704, 65503799), (65504004, 65504206), (65504132, 65504206), (65504325, 65504358), (65504325, 65504848), (65504657, 65504689), (65504837, 65505278), (65505203, 65505278), (65505206, 65505662), (65505503, 65505662), (65505590, 65505662), (65506259, 65506431), (65506385, 65506465), (65506385, 65506469), (65506385, 65506516)]\n",
      "  intron_indices: [(65497865, 65498681), (65498734, 65498968), (65502393, 65502636), (65503799, 65504132), (65503905, 65506259), (65504206, 65504325), (65504206, 65504325), (65504358, 65504657), (65505278, 65505503), (65505278, 65505590), (65505662, 65506385), (65505662, 65506385), (65505662, 65506385)]\n",
      "  stop_codons: []\n",
      "  five_prime_utr: \n",
      "  three_prime_utr: \n",
      "  exon_concat: None\n",
      "  full_mrna: GACGCAGCCCCACCGGTTGCGCAGTCCCTCCCCGCCCCCGCTCTCCCCTCCGCAGCCTGCAGCCCGAGACTTCTGTAAAGGACTGGGGCCCCGCAACTGGCCTCTCCTGCCCTCTTAAGCGCAGCGCCATTTTAGCAACGCAGAAGCCCGGCGCCGGGAAGCCTCAGCTCGCCTGAAGGCAGGTCCCCTCTGACGCCTCCGGGAGCCCAGGTTTCCCAGAGTCCTTGGGACGCAGCGACGAGTTGTGCTGCTATCTTAGCTGTCCTTATAGGCTGGCCATTCCAGGTGGTGGTATTTAGATAAAACCACTCAAACTCTGCAGTTTGGTCTTGGGGTTTGGAGGAAAGCTTTTATTTTTCTTCCTGCTCCGGTTCAGAAGGTCTGAAGCTCATACCTAACCAGGCATAACACAGAATCTGCAAAACAAAAACCCCTAAAAAAGCAGACCCAGAGCAGTGTAAACACTTCTGGGTGTGTCCCTGACTGGCTGCCCAAGGTCTCTGTGTCTTCGGAGACAAAGCCATTCGCTTAGTTGGTCTACTTTAAAAGGCCACTTGAACTCGCTTTCCATGGCGATTTGCCTTGTGAGCACTTTCAGGAGAGCCTGGAAGCTGAAAAACGGTAGAAAAATTTCCGTGCGGGCCGTGGGGGGCTGGCGGCAACTGGGGGGCCGCAGATCAGAGTGGGCCACTGGCAGCCAACGGCCCCCGGGGCTCAGGCGGGGAGCAGCTCTGTGGTGTGGGATTGAGGCGTTTTCCAAGAGTGGGTTTTCACGTTTCTAAGATTTCCCAAGCAGACAGCCCGTGCTGCTCCGATTTCTCGAACAAAAAAGCAAAACGTGTGGCTGTCTTGGGAGCAAGTCGCAGGACTGCAAGCAGTTGGGGGAGAAAGTCCGCCATTTTGCCACTTCTCAACCGTCCCTGCAAGGCTGGGGCTCAGTTGCGTAATGGAAAGTAAAGCCCTGAACTATCACACTTTAATCTTCCTTCAAAAGGTGGTAAACTATACCTACTGTCCCTCAAGAGAACACAAGAAGTGCTTTAAGAGGTATTTTAAAAGTTCCGGGGGTTTTGTGAGGTGTTTGATGACCCGTTTAAAATATGATTTCCATGTTTCTTTTGTCTAAAGTTTGCAGCTCAAATCTTTCCACACGCTAGTAATTTAAGTATTTCTGCATGTGTAGTTTGCATTCAAGTTCCATAAGCTGTTAAGAAAAATCTAGAAAAGTAAAACTAGAACCTATTTTTAACCGAAGAACTACTTTTTGCCTCCCTCACAAAGGCGGCGGAAGGTGATCGAATTCCGGTGATGCGAGTTGTTCTCCGTCTATAAATACGCCTCGCCCGAGCTGTGCGGTAGGCATTGAGGCAGCCAGCGCAGGGGCTTCTGCTGAGGGGGCAGGCGGAGCTTGAGGAAACCGCAGATAAGTTTTTTTCTCTTTGAAAGATAGAGATTAATACAACTACTTAAAAAATATAGTCAATAGGTTACTAAGATATTGCTTAGCGTTAAGTTTTTAACGTAATTTTAATAGCTTAAGATTTTAAGAGAAAATATGAAGACTTAGAAGAGTAGCATGAGGAAGGAAAAGATAAAAGGTTTCTAAAACATGACGGAGGTTGAGATGAAGCTTCTTCATGGAGTAAAAAATGTATTTAAAAGAAAATTGAGAGAAAGGACTACAGAGCCCCGAATTAATACCAATAGAAGGGCAATGCTTTTAGATTAAAATGAAGGTGACTTAAACAGCTTAAAGTTTAGTTTAAAAGTTGTAGGTGATTAAAATAATTTGAAGGCGATCTTTTAAAAAGAGATTAAACCGAAGGTGATTAAAAGACCTTGAAATCCATGACGCAGGGAGAATTGCGTCATTTAAAGCCTAGTTAACGCATTTACTAAACGCAGACGAAAATGGAAAGATTAATTGGGAGTGGTAGGATGAAACAATTTGGAGAAGATAGAAGTTTGAAGTGGAAAACTGGAAGACAGAAGTACGGGAAGGCGAAGAAAAGAATAGAGAAGATAGGGAAATTAGAAGATAAAAACATACTTTTAGAAGAAAAAAGATAAATTTAAACCTGAAAAGTAGGAAGCAGAAGAAAAAAGACAAGCTAGGAAACAAAAAGCTAAGGGCAAAATGTACAAACTTAGAAGAAAATTGGAAGATAGAAACAAGATAGAAAATGAAAATATTGTCAAGAGTTTCAGATAGAAAATGAAAAACAAGCTAAGACAAGTATTGGAGAAGTATAGAAGATAGAAAAATATAAAGCCAAAAATTGGATAAAATAGCACTGAAAAAATGAGGAAATTATTGGTAACCAATTTATTTTAAAAGCCCATCAATTTAATTTCTGGTGGTGCAGAAGTTAGAAGGTAAAGCTTGAGAAGATGAGGGTGTTTACGTAGACCAGAACCAATTTAGAAGAATACTTGAAGCTAGAAGGGGAAGTTGGTTAAAAATCACATCAAAAAGCTACTAAAAGGACTGGTGTAATTTAAAAAAAACTAAGGCAGAAGGCTTTTGGAAGAGTTAGAAGAATTTGGAAGGCCTTAAATATAGTAGCTTAGTTTGAAAAATGTGAAGGACTTTCGTAACGGAAGTAATTCAAGATCAAGAGTAATTACCAACTTAATGTTTTTGCATTGGACTTTGAGTTAAGATTATTTTTTAAATCCTGAGGACTAGCATTAATTGACAGCTGACCCAGGTGCTACACAGAAGTGGATTCAGTGAATCTAGGAAGACAGCAGCAGACAGGATTCCAGGAACCAGTGTTTGATGAAGCTAGGACTGAGGAGCAAGCGAGCAAGCAGCAGTTCGTGGTGAAGATAGGAAAAGAGTCCAGGAGCCAGTGCGATTTGGTGAAGGAAGCTAGGAAGAAGGAAGGAGCGCTAACGATTTGGTGGTGAAGCTAGGAAAAAGGATTCCAGGAAGGAGCGAGTGCAATTTGGTGATGAAGGTAGCAGGCGGCTTGGCTTGGCAACCACACGGAGGAGGCGAGCAGGCGTTGTGCGTAGAGGATCCTAGACCAGCATGCCAGTGTGCCAAGGCCACAGGGAAAGCGAGTGGTTGGTAAAAATCCGTGAGGTCGGCAATATGTTGTTTTTCTGGAACTTACTTATGGTAACCTTTTATTTATTTTCTAATATAATGGGGGAGTTTCGTACTGAGGTGTAAAGGGATTTATATGGGGACGTAGGCCGATTTCCGGGTGTTGTAGGTTTCTCTTTTTCAGGCTTATACTCATGAATCTTGTCTGAAGCTTTTGAGGGCAGACTGCCAAGTCCTGGAGAAATAGTAGATGGCAAGTTTGTGGGTTTTTTTTTTTTACACGAATTTGAGGAAAACCAAATGAATTTGATAGCCAAATTGAGACAATTTCAGCAAATCTGTAAGCAGTTTGTATGTTTAGTTGGGGTAATGAAGTATTTCAGTTTTGTGAATAGATGACCTGTTTTTACTTCCTCACCCTGAATTCGTTTTGTAAATGTAGAGTTTGGATGTGTAACTGAGGCGGGGGGGAGTTTTCAGTATTTTTTTTTGTGGGGGTGGGGGCAAAATATGTTTTCAGTTCTTTTTCCCTTAGGTCTGTCTAGAATCCTAAAGGCAAATGACTCAAGGTGTAACAGAAAACAAGAAAATCCAATATCAGGATAATCAGACCACCACAGGTTTACAGTTTATAGAAACTAGAGCAGTTCTCACGTTGAGGTCTGTGGAAGAGATGTCCATTGGAGAAATGGCTGGTAGTTACTCTTTTTTCCCCCCACCCCCTTAATCAGACTTTAAAAGTGCTTAACCCCTTAAACTTGTTATTTTTTACTTGAAGCATTTTGGGATGGTCTTAACAGGGAAGAGAGAGGGTGGGGGAGAAAATGTTTTTTTCTAAGATTTTCCACAGATGCTATAGTACTATTGACAAACTGGGTTAGAGAAGGAGTGTACCGCTGTGCTGTTGGCACGAACACCTTCAGGGACTGGAGCTGCTTTTATCCTTGGAAGAGTATTCCCAGTTGAAGCTGAAAAGTACAGCACAGTGCAGCTTTGGTTCATATTCAGTCATCTCAGGAGAACTTCAGAAGAGCTTGAGTAGGCCAAATGTTGAAGTTAAGTTTTCCAATAATGTGACTTCTTAAAAGTTTTATTAAAGGGGAGGGGCAAATATTGGCAATTAGTTGGCAGTGGCCTGTTACGGTTGGGATTGGTGGGGTGGGTTTAGGTAATTGTTTAGTTTATGATTGCAGATAAACTCATGCCAGAGAACTTAAAGTCTTAGAATGGAAAAAGTAAAGAAATATCAACTTCCAAGTTGGCAAGTAACTCCCAATGATTTAGTTTTTTTCCCCCCAGTTTGAATTGGGAAGCTGGGGGAAGTTAAATATGAGCCACTGGGTGTACCAGTGCATTAATTTGGGCAAGGAAAGTGTCATAATTTGATACTGTATCTGTTTTCCTTCAAAGTATAGAGCTTTTGGGGAAGGAAAGTATTGAACTGGGGGTTGGTCTGGCCTACTGGGCTGACATTAACTACAATTATGGGAAATGCAAAAGTTGTTTGGATATGGTAGTGTGTGGTTCTCTTTTGGAATTTTTTTCAGGTGATTTAATAATAATTTAAAACTACTATAGAAACTGCAGAGCAAAGGAAGTGGCTTAATGATCCTGAAGGGATTTCTTCTGATGGTAGCTTTTGTATTATCAAGTAAGATTCTATTTTCAGTTGTGTGTAAGCAAGTTTTTTTTTAGTGTAGGAGAAATACTTTTCCATTGTTTAACTGCAAAACAAGATGTTAAGGTATGCTTCAAAAATTTTGTAAATTGTTTATTTTAAACTTATCTGTTTGTAAATTGTAACTGATTAAGAATTGTGATAGTTCAGCTTGAATGTCTCTTAGAGGGTGGGCTTTTGTTGATGAGGGAGGGGAAACTTTTTTTTTTTCTATAGACTTTTTTCAGATAACATCTTCTGAGTCATAACCAGCCTGGCAGTATGATGGCCTAGATGCAGAGAAAACAGCTCCTTGGTGAATTGATAAGTAAAGGCAGAAAAGATTATATGTCATACCTCCATTGGGGAATAAGCATAACCCTGAGATTCTTACTACTGATGAGAACATTATCTGCATATGCCAAAAAATTTTAAGCAAATGAAAGCTACCAATTTAAAGTTACGGAATCTACCATTTTAAAGTTAATTGCTTGTCAAGCTATAACCACAAAAATAATGAATTGATGAGAAATACAATGAAGAGGCAATGTCCATCTCAAAATACTGCTTTTACAAAAGCAGAATAAAAGCGAAAAGAAATGAAAATGTTACACTACATTAATCCTGGAATAAAAGAAGCCGAAATAAATGAGAGATGAGTTGGGATCAAGTGGATTGAGGAGGCTGTGCTGTGTGCCAATGTTTCGTTTGCCTCAGACAGGTATCTCTTCGTTATCAGAAGAGTTGCTTCATTTCATCTGGGAGCAGAAAACAGCAGGCAGCTGTTAACAGATAAGTTTAACTTGCATCTGCAGTATTGCATGTTAGGGATAAGTGCTTATTTTTAAGAGCTGTGGAGTTCTTAAATATCAACCATGGCACTTTCTCCTGACCCCTTCCCTAGGGGATTTCAGGATTGAGAAATTTTTCCATCGAGCCTTTTTAAAATTGTAGGACTTGTTCCTGTGGGCTTCAGTGATGGGATAGTACACTTCACTCAGAGGCATTTGCATCTTTAAATAATTTCTTAAAAGCCTCTAAAGTGATCAGTGCCTTGATGCCAACTAAGGAAATTTGTTTAGCATTGAATCTCTGAAGGCTCTATGAAAGGAATAGCATGATGTGCTGTTAGAATCAGATGTTACTGCTAAAATTTACATGTTGTGATGTAAATTGTGTAGAAAACCATTAAATCATTCAAAATAATAAACTATTTTTATTAGAGAATGTATACTTTTAGAAAGCTGTCTCCTTATTTAAATAAAATAGTGTTTGTCTGTAGTTCAGTGTTGGGGCAATCTTGGGGGGGATTCTTCTCTAATCTTTCAGAAACTTTGTCTGCGAACACTCTTTAATGGACCAGATCAGGATTTGAGCGGAAGAACGAATGTAACTTTAAGGCAGGAAAGACAAATTTTATTCTTCATAAAGTGATGAGCATATAATAATTCCAGGCACATGGCAATAGAGGCCCTCTAAATAAGGAATAAATAACCTCTTAGACAGGTGGGAGATTATGATCAGAGTAAAAGGTAATTACACATTTTATTTCCAGAAAGTCAGGGGTCTATAAATTGACAGTGATTAGAGTAATACTTTTTCACATTTCCAAAGTTTGCATGTTAACTTTAAATGCTTACAATCTTAGAGTGGTAGGCAATGTTTTACACTATTGACCTTATATAGGGAAGGGAGGGGGTGCCTGTGGGGTTTTAAAGAATTTTCCTTTGCAGAGGCATTTCATCCTTCATGAAGCCATTCAGGATTTTGAATTGCATATGAGTGCTTGGCTCTTCCTTCTGTTCTAGTGAGTGTATGAGACCTTGCAGTGAGTTTATCAGCATACTCAAAATTTTTTTCCTGGAATTTGGAGGGATGGGAGGAGGGGGTGGGGCTTACTTGTTGTAGCTTTTTTTTTTTTTACAGACTTCACAGAGAATGCAGTTGTCTTGACTTCAGGTCTGTCTGTTCTGTTGGCAAGTAAATGCAGTACTGTTCTGATCCCGCTGCTATTAGAATGCATTGTGAAACGACTGGAGTATGATTAAAAGTTGTGTTCCCCAATGCTTGGAGTAGTGATTGTTGAAGGAAAAAATCCAGCTGAGTGATAAAGGCTGAGTGTTGAGGAAATTTCTGCAGTTTTAAGCAGTCGTATTTGTGATTGAAGCTGAGTACATTTTGCTGGTGTATTTTTAGGTAAAATGCTTTTTGTTCATTTCTGGTGGTGGGAGGGGACTGAAGCCTTTAGTCTTTTCCAGATGCAACCTTAAAATCAGTGACAAGAAACATTCCAAACAAGCAACAGTCTTCAAGAAATTAAACTGGCAAGTGGAAATGTTTAAACAGTTCAGTGATCTTTAGTGCATTGTTTATGTGTGGGTTTCTCTCTCCCCTCCCTTGGTCTTAATTCTTACATGCAGGAACACTCAGCAGACACACGTATGCGAAGGGCCAGAGAAGCCAGACCCAGTAAGAAAAAATAGCCTATTTACTTTAAATAAACCAAACATTCCATTTTAAATGTGGGGATTGGGAACCACTAGTTCTTTCAGATGGTATTCTTCAGACTATAGAAGGAGCTTCCAGTTGAATTCACCAGTGGACAAAATGAGGAAAACAGGTGAACAAGCTTTTTCTGTATTTACATACAAAGTCAGATCAGTTATGGGACAATAGTATTGAATAGATTTCAGCTTTATGCTGGAGTAACTGGCATGTGAGCAAACTGTGTTGGCGTGGGGGTGGAGGGGTGAGGTGGGCGCTAAGCCTTTTTTTAAGATTTTTCAGGTACCCCTCACTAAAGGCACCGAAGGCTTAAAGTAGGACAACCATGGAGCCTTCCTGTGGCAGGAGAGACAACAAAGCGCTATTATCCTAAGGTCAAGAGAAGTGTCAGCCTCACCTGATTTTTATTAGTAATGAGGACTTGCCTCAACTCCCTCTTTCTGGAGTGAAGCATCCGAAGGAATGCTTGAAGTACCCCTGGGCTTCTCTTAACATTTAAGCAAGCTGTTTTTATAGCAGCTCTTAATAATAAAGCCCAAATCTCAAGCGGTGCTTGAAGGGGAGGGAAAGGGGGAAAGCGGGCAACCACTTTTCCCTAGCTTTTCCAGAAGCCTGTTAAAAGCAAGGTCTCCCCACAAGCAACTTCTCTGCCACATCGCCACCCCGTGCCTTTTGATCTAGCACAGACCCTTCACCCCTCACCTCGATGCAGCCAGTAGCTTGGATCCTTGTGGGCATGATCCATAATCGGTTTCAAGGTAACGATGGTGTCGAGGTCTTTGGTGGGTTGAACTATGTTAGAAAAGGCCATTAATTTGCCTGCAAATTGTTAACAGAAGGGTATTAAAACCACAGCTAAGTAGCTCTATTATAATACTTATCCAGTGACTAAAACCAACTTAAACCAGTAAGTGGAGAAATAACATGTTCAAGAACTGTAATGCTGGGTGGGAACATGTAACTTGTAGACTGGAGAAGATAGGCATTTGAGTGGCTGAGAGGGCTTTTGGGTGGGAATGCAAAAATTCTCTGCTAAGACTTTTTCAGGTGAACATAACAGACTTGGCCAAGCTAGCATCTTAGCGGAAGCTGATCTCCAATGCTCTTCAGTAGGGTCATGAAGGTTTTTCTTTTCCTGAGAAAACAACACGTATTGTTTTCTCAGGTTTTGCTTTTTGGCCTTTTTCTAGCTTAAAAAAAAAAAAAGCAAAAGATGCTGGTGGTTGGCACTCCTGGTTTCCAGGACGGGGTTCAAATCCCTGCGGCGTCTTTGCTTTGACTACTAATCTGTCTTCAGGACTCTTTCTGTATTTCTCCTTTTCTCTGCAGGTGCTAGTTCTTGGAGTTTTGGGGAGGTGGGAGGTAACAGCACAATATCTTTGAACTATATACATCCTTGATGTATAATTTGTCAGGAGCTTGACTTGATTGTATATTCATATTTACACGAGAACCTAATATAACTGCCTTGTCTTTTTCAGGTAATAGCCTGCAGCTGGTGTTTTGAGAAGCCCTACTGCTGAAAACTTAACAATTTTGTGTAATAAAAATGGAGAAGCTCTAAATTGTTGTGGTTCTTTTGTGAATAAAAAAATCTTGATTGGGGAAAAAA\n",
      "  cds_start: 65497687\n",
      "  cds_end: 65506516\n",
      "  strand: +\n",
      "  gene_type: ['lncRNA']\n",
      "  utr_indices: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__str__ returned non-string (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgene_to_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMALAT1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: __str__ returned non-string (type NoneType)"
     ]
    }
   ],
   "source": [
    "print(gene_to_data['MALAT1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7856fbebb56642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:07:56.107515Z",
     "start_time": "2025-09-17T21:07:56.105251Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "#plot_res(model,X,y,df_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c63d66730ac4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:08:00.090139Z",
     "start_time": "2025-09-17T21:08:00.061577Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f852e3a82470f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:08:10.329476Z",
     "start_time": "2025-09-17T21:08:10.327039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missing: CAI_score_global_CDS, 'sense_avg_accessibility', RNaseH1_Krel_score_R7_krel, Modification_min_distance_to_3prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f497ab4fc00a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:08:10.380713Z",
     "start_time": "2025-09-17T21:08:10.376141Z"
    }
   },
   "outputs": [],
   "source": [
    "from features.mod_features import compute_mod_min_distance_to_3prime\n",
    "\n",
    "# generate MOE 20-mers\n",
    "for gene, df in dfs.items():\n",
    "    df.loc[:, 'Modification_min_distance_to_3prime'] = compute_mod_min_distance_to_3prime('MMMMMddddddddddMMMMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78313c380856e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:43:38.973052Z",
     "start_time": "2025-09-17T21:43:38.758442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Load all batch files from the new output folder\n",
    "files = sorted(glob.glob(f\"out/batch_*.csv\"))\n",
    "df_all = pd.concat([pd.read_csv(f) for f in files], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21bc0fc19edeee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:43:42.378878Z",
     "start_time": "2025-09-17T21:43:42.366988Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995154a94bcece1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:47:28.850704Z",
     "start_time": "2025-09-17T21:47:19.934003Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc521ad6b8751d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T21:57:50.115370Z",
     "start_time": "2025-09-17T21:57:50.096666Z"
    }
   },
   "outputs": [],
   "source": [
    "malat_scores = model.predict(df_all[selected_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459df770ce0791ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T22:08:35.831581Z",
     "start_time": "2025-09-17T22:08:35.111859Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "\n",
    "# Assuming you already have get_antisense(seq: str) -> str defined\n",
    "# get_antisense, for some reason numba doesn't work well\n",
    "\n",
    "df_all[\"score\"] = malat_scores\n",
    "\n",
    "df_all[\"sense\"] = df_all[SEQUENCE].astype(str).str.translate(tbl).str[::-1]\n",
    "(\n",
    "    df_all.assign(score=malat_scores)\n",
    "    .sort_values(\"score\", ascending=False)   # sort by score\n",
    "    .to_csv(\"malat_scores_model2.csv\", index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5a85bc6fc72ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T22:08:36.805397Z",
     "start_time": "2025-09-17T22:08:36.800379Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sorted = df_all.sort_values('score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6eb9130b4f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T22:10:25.003177Z",
     "start_time": "2025-09-17T22:08:42.898Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install requests\n",
    "import math, time, threading, urllib.parse, requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "UA = {\"User-Agent\": \"python-requests gggenome/greedy\"}\n",
    "\n",
    "def _ggg_hits_leq_json(seq, k, db=\"hg38\", timeout=60, retries=2):\n",
    "    \"\"\"Count hits with <=k mismatches via GGGenome JSON; fallback to CSV if needed.\"\"\"\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    q = urllib.parse.quote(s)\n",
    "    url_json = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.json\"\n",
    "    url_csv  = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.csv?download\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url_json, headers=UA, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            try:\n",
    "                data = r.json()\n",
    "            except ValueError:\n",
    "                raise RuntimeError(\"JSON parse failed\")\n",
    "            if isinstance(data, list):\n",
    "                return len(data)\n",
    "            if isinstance(data, dict):\n",
    "                if \"results\" in data and isinstance(data[\"results\"], list): return len(data[\"results\"])\n",
    "                if \"hits\" in data and isinstance(data[\"hits\"], list):       return len(data[\"hits\"])\n",
    "                return sum(len(v) for v in data.values() if isinstance(v, list))\n",
    "            return 0\n",
    "        except Exception:\n",
    "            # greedy CSV fallback\n",
    "            try:\n",
    "                r2 = requests.get(url_csv, headers=UA, timeout=timeout)\n",
    "                r2.raise_for_status()\n",
    "                return sum(1 for ln in r2.text.splitlines() if ln and not ln.startswith(\"#\"))\n",
    "            except Exception:\n",
    "                if attempt < retries:\n",
    "                    continue\n",
    "                return 0\n",
    "    return 0\n",
    "\n",
    "def _d123_for_sequence(seq, db=\"hg38\"):\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    if not s:\n",
    "        return (s, 0, 0, 0)\n",
    "    L = len(s)\n",
    "    k_allowed = max(0, math.floor(0.25 * L))  # GGGenome cap\n",
    "    k0 = _ggg_hits_leq_json(s, 0, db=db)\n",
    "    k1 = _ggg_hits_leq_json(s, 1, db=db) if k_allowed >= 1 else 0\n",
    "    k2 = _ggg_hits_leq_json(s, 2, db=db) if k_allowed >= 2 else 0\n",
    "    k3 = _ggg_hits_leq_json(s, 3, db=db) if k_allowed >= 3 else 0\n",
    "    d1 = max(0, k1 - k0)\n",
    "    d2 = max(0, k2 - k1)\n",
    "    d3 = max(0, k3 - k2)\n",
    "    return (s, d1, d2, d3)\n",
    "\n",
    "def add_gggenome_d123(main_df, seq_col=\"SEQUENCE\", db=\"hg38\", *, max_workers=32, print_every=10):\n",
    "    seqs = (main_df[seq_col].astype(str).str.upper().str.replace(\"U\", \"T\", regex=False))\n",
    "    uniq = seqs.dropna().unique().tolist()\n",
    "    N = len(uniq)\n",
    "    print(f\"[GGG] Unique sequences: {N} | db={db} | workers={max_workers}\")\n",
    "\n",
    "    cache = {}\n",
    "    lock = threading.Lock()\n",
    "    t0 = time.perf_counter()\n",
    "    errs = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = {ex.submit(_d123_for_sequence, s, db): s for s in uniq}\n",
    "        done = 0\n",
    "        for fut in as_completed(futs):\n",
    "            s = futs[fut]\n",
    "            try:\n",
    "                s_key, d1, d2, d3 = fut.result()\n",
    "            except Exception:\n",
    "                d1 = d2 = d3 = 0\n",
    "                with lock:\n",
    "                    errs += 1\n",
    "            with lock:\n",
    "                cache[s] = (d1, d2, d3)\n",
    "                done += 1\n",
    "                if (done == 1) or (done % print_every == 0) or (done == N):\n",
    "                    elapsed = time.perf_counter() - t0\n",
    "                    rps = done / elapsed if elapsed > 0 else 0.0\n",
    "                    print(f\"[GGG] {done}/{N} cached | ~{rps:.1f} seq/s | errors={errs}\")\n",
    "\n",
    "    main_df[\"ggg_d1\"] = seqs.map(lambda s: cache.get(s, (0, 0, 0))[0])\n",
    "    main_df[\"ggg_d2\"] = seqs.map(lambda s: cache.get(s, (0, 0, 0))[1])\n",
    "    main_df[\"ggg_d3\"] = seqs.map(lambda s: cache.get(s, (0, 0, 0))[2])\n",
    "\n",
    "    print(f\"[GGG] Finished in {time.perf_counter() - t0:.1f}s. Added columns: ggg_d1, ggg_d2, ggg_d3\")\n",
    "    return main_df\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "# main_df = main_df[main_df[SENSE_START] != -1]\n",
    "result = add_gggenome_d123(df_sorted[:100], seq_col='sense', db=\"hg38\", max_workers=100, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da04a7639168ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T22:21:55.591734Z",
     "start_time": "2025-09-17T22:21:55.586341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show up to 200 characters per column\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "# Show more columns across the screen\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Optionally, widen the console display\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(result[:30][[SEQUENCE, 'sense_start', 'ggg_d1', 'ggg_d2', 'at_skew', 'gc_content', 'on_target_fold_openness_normalized40_15', 'sense_avg_accessibility', 'RNaseH1_Krel_score_R7_krel']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13e4688def2b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T22:22:32.982136Z",
     "start_time": "2025-09-17T22:22:32.976787Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sorted.tail(30)[['on_target_fold_openness_normalized40_15']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826aff404f2adaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's generate LNA GFP sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b83cac69a89e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:16:40.795813Z",
     "start_time": "2025-09-19T15:16:40.768977Z"
    }
   },
   "outputs": [],
   "source": [
    "# GFP_IN_YEAST = (\n",
    "#     'ATGGTtAGtAAaGGaGAaGAGTTgTTCACaGGaGTGGTGCCCATCCTGGTCGAGCTGGACGGCGACGTAAACGGCCACAAGTTCAGCGTGTCCGGCGAGGGCGAGGGCGATGCCACCTACGGCAAGCTGACCCTGAAGTTCATCTGCACCACCGGCAAGCTGCCCGTGCCCTGGCCCACCCTCGTGACCACCCTGACCTACGGCGTGCAGTGCTTCAGCCGCTACCCCGACCACATGAAGCAGCACGACTTCTTCAAGTCCGCCATGCCCGAAGGCTACGTCCAGGAGCGCACCATCTTCTTCAAGGACGACGGCAACTACAAGACCCGCGCCGAGGTGAAGTTCGAGGGCGACACCCTGGTGAACCGCATCGAGCTGAAGGGCATCGACTTCAAGGAGGACGGCAACATCCTGGGGCACAAGCTGGAGTACAACTACAACAGCCACAACGTCTATATCATGGCCGACAAGCAGAAGAACGGCATCAAGGTGAACTTCAAGATCCGCCACAACATCGAGGACGGCAGCGTGCAGCTCGCCGACCACTACCAGCAGAACACCCCCATCGGCGACGGCCCCGTGCTGCTGCCCGACAACCACTACCTGAGCACCCAGTCCGCCCTGAGCAAAGACCCCAACGAGAAGCGCGATCACATGGTCCTGCTGGAGTTCGTGACCGCCGCCGGGATCACTCTCGGCATGGACGAGCTGTACAAGGGTGCTGGGGCAggtacCCCTAAAGATCCAGCCAAACCTCCGGCCAcGGCACAAGTTGTGGGATGGCCACCGGTGAGATCATACCGGAAGAACGTGATGGTTTCCTGCCAAAAATCAAGCGGTGGCCCGGAGGCGGCGGCGTTCGTGAAGTAA'\n",
    "#     .upper())\n",
    "\n",
    "GFP_IN_HUMAN = (\n",
    "\"ctttttcgcaacgggtttgccgccagaacacaggaccggtgccaccatggtgagcaagggcgaggagctgttcaccggggtggtgcccatcctggtcgagctggacggcgacgtaaacggccacaagttcagcgtgtccggcgagggcgagggcgatgccacctacggcaagctgaccctgaagttcatctgcaccaccggcaagctgcccgtgccctggcccaccctcgtgaccaccctgacctacggcgtgcagtgcttcagccgctaccccgaccacatgaagcagcacgacttcttcaagtccgccatgcccgaaggctacgtccaggagcgcaccatcttcttcaaggacgacggcaactacaagacccgcgccgaggtgaagttcgagggcgacaccctggtgaaccgcatcgagctgaagggcatcgacttcaaggaggacggcaacatcctggggcacaagctggagtacaactacaacagccacaacgtctatatcatggccgacaagcagaagaacggcatcaaggtgaacttcaagatccgccacaacatcgaggacggcagcgtgcagctcgccgaccactaccagcagaacacccccatcggcgacggccccgtgctgctgcccgacaaccactacctgagcacccagtccgccctgagcaaagaccccaacgagaagcgcgatcacatggtcctgctggagttcgtgaccgccgccgggatcactctcggcatggacgagctgtacaagcccaagaaaaagcggaaagtgggatccggcgcaacaaacttctctctgctgaaacaagccggagatgtcgaagagaatcctggaccgaccgagtacaagcccacggtgcgcctcgccacccgcgacgacgtccccagggccgtacgcaccctcgccgccgcgttcgccgactaccccgccacgcgccacaccgtcgatccggaccgccacatcgagcgggtcaccgagctgcaagaactcttcctcacgcgcgtcgggctcgacatcggcaaggtgtgggtcgcggacgacggcgccgcggtggcggtctggaccacgccggagagcgtcgaagcgggggcggtgttcgccgagatcggcccgcgcatggccgagttgagcggttcccggctggccgcgcagcaacagatggaaggcctcctggcgccgcaccggcccaaggagcccgcgtggttcctggccaccgtcggagtctcgcccgaccaccagggcaagggtctgggcagcgccgtcgtgctccccggagtggaggcggccgagcgcgccggggtgcccgccttcctggagacctccgcgccccgcaacctccccttctacgagcggctcggcttcaccgtcaccgccgacgtcgaggtgcccgaaggaccgcgcacctggtgcatgacccgcaagcccggtgcctgaacgcgttaagtcgacaatcaacctctggattacaaaatttgtgaaagattgactggtattcttaactatgttgctccttttacgctatgtggatacgctgctttaatgcctttgtatcatgctattgcttcccgtatggctttcattttctcctccttgtataaatcctggttgctgtctctttatgaggagttgtggcccgttgtcaggcaacgtggcgtggtgtgcactgtgtttgctgacgcaacccccactggttggggcattgccaccacctgtcagctcctttccgggactttcgctttccccctccctattgccacggcggaactcatcgccgcctgccttgcccgctgctggacaggggctcggctgttgggcactgacaattccgtggtgttgtcggggaaatcatcgtcctttccttggctgctcgcctgtgttgccacctggattctgcgcgggacgtccttctgctacgtcccttcggccctcaatccagcggaccttccttcccgcggcctgctgccggctctgcggcctcttccgcgtcttcgccttcgccctcagacgagtcggatctccctttgggccgcctccccgcgtcgactttaagaccaatgacttacaaggcagctgtagatcttagccactttttaaaagaaaaggggggactggaagggctaattcactcccaacgaagacaagatctgctttttgcttgtactgggtctctctggttagaccagatctgagcctgggagctctctggctaactagggaacccactgcttaagcctcaataaagcttgccttgagtgcttcaagtagtgtgtgcccgtctgttgtgtgactctggtaactagagatccctcagacccttttagtcagtgtggaaaatctctagcagggcccgtttaaacccgctgatcagcctcgactgtgccttctagttgccagccatctgttgtttgcccctcccccgtgccttccttgaccctggaaggtgccactcccactgtcctttcctaataaa\".upper()\n",
    ")\n",
    "# GFP + Degron x <= 842\n",
    "# NLS 843 <= x<= 893\n",
    "# 3UTR 1615 <= x <= 1848\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1bd53a849efe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:16:42.351502Z",
     "start_time": "2025-09-19T15:16:42.327086Z"
    }
   },
   "outputs": [],
   "source": [
    "GFP_IN_HUMAN[633:633+16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d49f6282df681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:16:43.090105Z",
     "start_time": "2025-09-19T15:16:43.063906Z"
    }
   },
   "outputs": [],
   "source": [
    "GFP_IN_HUMAN[679:679+16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa91eddd19f261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:16:59.235551Z",
     "start_time": "2025-09-19T15:16:59.202092Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "import pandas as pd\n",
    "\n",
    "# GFP_YEAST_END = len(GFP_IN_YEAST) - 3\n",
    "GFP_HUMAN_END = len(GFP_IN_HUMAN)\n",
    "LNA_SIZE = 16\n",
    "\n",
    "def get_init_df(target_mrna, end):\n",
    "    candidates = []\n",
    "    sense_starts = []\n",
    "    sense_lengths = []\n",
    "    sense_starts_from_end = []\n",
    "\n",
    "    for i in range(0, len(target_mrna) - (LNA_SIZE - 1)):\n",
    "        target = target_mrna[i: i + LNA_SIZE]\n",
    "        candidates.append(get_antisense(str(target)))\n",
    "        sense_starts.append(i)\n",
    "        sense_lengths.append(LNA_SIZE)\n",
    "        sense_starts_from_end.append(end - i)\n",
    "    df = pd.DataFrame(\n",
    "        {SEQUENCE: candidates, SENSE_START: sense_starts,\n",
    "         SENSE_LENGTH: sense_lengths, \"sense_start_from_end\": sense_starts_from_end})\n",
    "    return df\n",
    "\n",
    "\n",
    "# df_yeast = get_init_df(GFP_IN_YEAST, GFP_YEAST_END)\n",
    "df_human = get_init_df(GFP_IN_HUMAN, GFP_HUMAN_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04111a58b965b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:17:18.572961Z",
     "start_time": "2025-09-19T15:17:18.539677Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "import pandas as pd\n",
    "\n",
    "# df_yeast[CANONICAL_GENE] = 'YEAST_GFP'\n",
    "df_human[CANONICAL_GENE] = 'HUMAN_GFP'\n",
    "dataframes = [df_human]\n",
    "\n",
    "# df_yeast['sense_exon'] = 1\n",
    "df_human['sense_exon'] = 1\n",
    "# df_yeast['sense_intron'] = 0\n",
    "df_human['sense_intron'] = 0\n",
    "# df_yeast['sense_utr'] = 0\n",
    "df_human['sense_utr'] = [1 if sense_start > 842 else 0 for sense_start in df_human[SENSE_START]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c8c63c1e68429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:17:26.083059Z",
     "start_time": "2025-09-19T15:17:25.934487Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from asodesigner.process_utils import LocusInfo\n",
    "from scripts.data_genertion.data_handling import get_populate_fold\n",
    "\n",
    "genes_u = ['YEAST_GFP', 'HUMAN_GFP', 'MALAT1']\n",
    "gene_to_data = {'YEAST_GFP': LocusInfo(), 'HUMAN_GFP': LocusInfo(), 'MALAT1': LocusInfo()}\n",
    "# gene_to_data['YEAST_GFP'].full_mrna = GFP_IN_YEAST\n",
    "gene_to_data['HUMAN_GFP'].full_mrna = GFP_IN_HUMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d54c2f22f5a3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:17:52.620999Z",
     "start_time": "2025-09-19T15:17:52.332808Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_genertion.data_handling import populate_features\n",
    "\n",
    "dfs = dict()\n",
    "# dfs['YEAST_GFP'] = df_yeast\n",
    "dfs['HUMAN_GFP'] = df_human\n",
    "SEQUENCES = {}\n",
    "for target in ['HUMAN_GFP']:\n",
    "# for target in ['YEAST_GFP', 'HUMAN_GFP']:\n",
    "    SEQUENCES[target] = gene_to_data[target].full_mrna\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    df[TREATMENT_PERIOD] = 24  # keep constant for all\n",
    "    df[VOLUME] = 1000  # keep constant for all\n",
    "    df['log_volume'] = np.log(df[VOLUME])\n",
    "    df['normalized_start'] = df[SENSE_START] / len(SEQUENCES[gene])\n",
    "    df['normalized_sense_start_from_end'] = df['sense_start_from_end'] / len(SEQUENCES[gene])\n",
    "    easy_to_populate = ['at_skew', 'gc_content', 'gc_content_3_prime_5', 'gc_skew', 'hairpin_score',\n",
    "                        'homooligo_count', 'internal_fold', 'nucleotide_diversity', 'self_energy', 'stop_codon_count',\n",
    "                        'at_rich_region_score', 'poly_pyrimidine_stretch']\n",
    "    populate_features(df, easy_to_populate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacc16cb4318ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:18:14.121512Z",
     "start_time": "2025-09-19T15:18:14.080591Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_populate_fold(df, genes_u, gene_to_data, fold_variants=[(40, 15)]):\n",
    "    from asodesigner.fold import calculate_energies, get_weighted_energy\n",
    "    from asodesigner.util import get_antisense\n",
    "\n",
    "    all_data_human_gene_premrna_no_nan = df.copy()\n",
    "\n",
    "    # Comment out the long cases for quick running\n",
    "    for (window_size, step_size) in fold_variants:\n",
    "\n",
    "        on_target_fold = 'on_target_fold_openness' + str(window_size) + '_' + str(step_size)\n",
    "        on_target_fold_normalized = 'on_target_fold_openness_normalized' + str(window_size) + '_' + str(step_size)\n",
    "        all_data_human_gene_premrna_no_nan[on_target_fold] = np.zeros_like(all_data_human_gene_premrna_no_nan[SEQUENCE],\n",
    "                                                                           dtype=np.float64)\n",
    "        all_data_human_gene_premrna_no_nan[on_target_fold_normalized] = np.zeros_like(\n",
    "            all_data_human_gene_premrna_no_nan[SEQUENCE], dtype=np.float64)\n",
    "\n",
    "        for gene in genes_u:\n",
    "\n",
    "            target = gene_to_data[gene].full_mrna\n",
    "            gene_rows = all_data_human_gene_premrna_no_nan[all_data_human_gene_premrna_no_nan[CANONICAL_GENE] == gene]\n",
    "            energies = calculate_energies(str(target), step_size, window_size)\n",
    "\n",
    "            for index, row in gene_rows.iterrows():\n",
    "                antisense = row[SEQUENCE]\n",
    "                sense = get_antisense(antisense)\n",
    "                l = row[SENSE_LENGTH]\n",
    "                sense_start = row[SENSE_START]\n",
    "                mean_fold = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                mean_fold_end = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                mean_fold_start = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                if mean_fold > 100:\n",
    "                    print(energies)\n",
    "                    print(\"Weird: \", mean_fold)\n",
    "                    print(\"Sense_start \", sense_start)\n",
    "                    print(\"Sense_length \", l)\n",
    "                    print(\"Gene: \", gene)\n",
    "                    mean_fold = 0\n",
    "                all_data_human_gene_premrna_no_nan.loc[index, on_target_fold] = mean_fold\n",
    "                all_data_human_gene_premrna_no_nan.loc[index, on_target_fold_normalized] = mean_fold / l\n",
    "    return all_data_human_gene_premrna_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9219459f3d66eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:18:20.663057Z",
     "start_time": "2025-09-19T15:18:19.919096Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_genertion.data_handling import get_populate_fold\n",
    "\n",
    "# dfs['YEAST_GFP'] = df_yeast\n",
    "dfs['HUMAN_GFP'] = df_human\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    fold_variants = [(40, 15)]\n",
    "\n",
    "    df = get_populate_fold(df, ['YEAST_GFP', 'HUMAN_GFP'], gene_to_data, fold_variants=fold_variants)\n",
    "    dfs[gene] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b741973dc97c2cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:18:44.379623Z",
     "start_time": "2025-09-19T15:18:44.345285Z"
    }
   },
   "outputs": [],
   "source": [
    "from hybridization.hybridization_features import get_exp_psrna_hybridization\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    df.loc[:, 'exp_ps_hybr'] = [\n",
    "        get_exp_psrna_hybridization(antisense.replace('T', 'U'), temp=37) for\n",
    "        antisense in df[SEQUENCE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e984282a8438c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:18:48.331205Z",
     "start_time": "2025-09-19T15:18:48.301737Z"
    }
   },
   "outputs": [],
   "source": [
    "from features.mod_features import compute_mod_min_distance_to_3prime\n",
    "\n",
    "# generate LNA 16-mers\n",
    "for gene, df in dfs.items():\n",
    "    df.loc[:, 'Modification_min_distance_to_3prime'] = compute_mod_min_distance_to_3prime('LLLddddddddddLLL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845a217a41c7d20d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:25:26.842644Z",
     "start_time": "2025-09-19T15:19:15.869178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 0 to 500...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'out/MALAT1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     70\u001b[39m batch[\u001b[33m'\u001b[39m\u001b[33msense_avg_accessibility\u001b[39m\u001b[33m'\u001b[39m] = batch.apply(\n\u001b[32m     71\u001b[39m     compute_sense_accessibility,\n\u001b[32m     72\u001b[39m     axis=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     access_size=ACCESS_SIZE,\n\u001b[32m     77\u001b[39m )\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Save batch to the new folder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mout/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgene\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/batch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mend_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aso_design/lib/python3.11/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'out/MALAT1'"
     ]
    }
   ],
   "source": [
    "# Missing: CAI_score_global_CDS, 'sense_avg_accessibility', RNaseH1_Krel_score_R7_krel, Modification_min_distance_to_3prime\n",
    "\n",
    "from yehuda_code.Folding_Functions import get_sense_with_flanks\n",
    "from yehuda_code.access_calculator import AccessCalculator\n",
    "\n",
    "FLANK_SIZE = 120\n",
    "ACCESS_SIZE = 13\n",
    "SEED_SIZE = 13\n",
    "SEED_SIZES = [SEED_SIZE * m for m in range(1, 4)]\n",
    "ACCESS_WIN_SIZE = 80\n",
    "\n",
    "\n",
    "def compute_sense_accessibility(row, flank_size, access_win_size, seed_sizes, access_size, min_gc=0, max_gc=100,\n",
    "                                gc_ranges=1):\n",
    "    try:\n",
    "        # Skip invalid rows\n",
    "        if row['sense_start'] == -1 or pd.isna(row['sense_with_flank_120nt']) or row['sense_with_flank_120nt'] == \"\":\n",
    "            return None\n",
    "\n",
    "        seq = row[f'sense_with_flank_{flank_size}nt']\n",
    "        sense_start = row['sense_start']\n",
    "        sense_length = row['sense_length']\n",
    "\n",
    "        # Calculate accessibility\n",
    "        df_access = AccessCalculator.calc(\n",
    "            seq, access_size,\n",
    "            min_gc, max_gc, gc_ranges,\n",
    "            access_win_size, seed_sizes\n",
    "        )\n",
    "\n",
    "        flank_start = max(0, sense_start - flank_size)\n",
    "        sense_start_in_flank = sense_start - flank_start\n",
    "        sense_end_in_flank = sense_start_in_flank + sense_length\n",
    "\n",
    "        if 0 <= sense_start_in_flank < len(df_access) and sense_end_in_flank <= len(df_access):\n",
    "            values = df_access['avg_access'].iloc[sense_start_in_flank:sense_end_in_flank].dropna()\n",
    "            return values.mean() if not values.empty else None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row.name} | seq start: {row['sense_start']} | error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    FLANKED_SENSE_COL = f'sense_with_flank_{FLANK_SIZE}nt'\n",
    "\n",
    "    val = gene_to_data[gene].full_mrna\n",
    "    df['pre_mrna_sequence'] = [val] * len(df)\n",
    "\n",
    "    # Create new column with flanked sequences\n",
    "    df[FLANKED_SENSE_COL] = df.apply(\n",
    "        lambda row: get_sense_with_flanks(\n",
    "            row['pre_mrna_sequence'],\n",
    "            row['sense_start'],\n",
    "            row['sense_length'],\n",
    "            flank_size=FLANK_SIZE\n",
    "        ) if row['sense_start'] != -1 else \"\",  # Handle cases where sense was not found\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    batch_size = 500\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "        print(f\"Processing rows {start_idx} to {end_idx}...\")\n",
    "\n",
    "        batch['sense_avg_accessibility'] = batch.apply(\n",
    "            compute_sense_accessibility,\n",
    "            axis=1,\n",
    "            flank_size=FLANK_SIZE,\n",
    "            access_win_size=ACCESS_WIN_SIZE,\n",
    "            seed_sizes=SEED_SIZES,\n",
    "            access_size=ACCESS_SIZE,\n",
    "        )\n",
    "\n",
    "        # Save batch to the new folder\n",
    "        batch.to_csv(f\"out/{gene}/batch_{start_idx}_{end_idx}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8625cdf898242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:25:38.104264Z",
     "start_time": "2025-09-19T15:25:38.032793Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Load all batch files from the new output folder\n",
    "files = sorted(glob.glob(f\"out/HUMAN_GFP/batch_*.csv\"))\n",
    "df_human = pd.concat([pd.read_csv(f) for f in files], axis=0)\n",
    "\n",
    "# files = sorted(glob.glob(f\"out/YEAST_GFP/batch_*.csv\"))\n",
    "# df_yeast = pd.concat([pd.read_csv(f) for f in files], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec49cbc7f8911f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:26:00.159713Z",
     "start_time": "2025-09-19T15:25:57.939461Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from asodesigner.features.RNaseH_features import rnaseh1_dict, compute_rnaseh1_score\n",
    "\n",
    "best_window_start_krel = {\n",
    "    'R4a_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 3, 18: 2, 19: 4, 20: 3, 21: 0, 22: 0, 25: 0},\n",
    "    'R4b_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 1, 18: 3, 19: 1, 20: 3, 21: 0, 22: 0, 25: 0},\n",
    "    'R7_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 3, 17: 2, 18: 4, 19: 6, 20: 4, 21: 0, 22: 0, 25: 0},\n",
    "}\n",
    "\n",
    "for exp in ['R4a_krel', 'R4b_krel', 'R7_krel']:\n",
    "    weights = rnaseh1_dict(exp)\n",
    "\n",
    "\n",
    "    def score_row(row):\n",
    "        length = len(row['Sequence'])\n",
    "        pos = best_window_start_krel.get(exp, {}).get(length, 0)\n",
    "        return compute_rnaseh1_score(row['Sequence'], weights, window_start=pos)\n",
    "\n",
    "    col_name = f\"RNaseH1_Krel_score_{exp}\"\n",
    "\n",
    "    # Yeast should have similar motifs, perhaps\n",
    "    df_human[col_name] = df_human.apply(score_row, axis=1)\n",
    "    # df_yeast[col_name] = df_yeast.apply(score_row, axis=1)\n",
    "\n",
    "RNaseH1_Krel_features_best = [f\"RNaseH1_Krel_score_{exp}\" for exp in ['R4a_krel', 'R4b_krel', 'R7_krel']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59da38fa425784e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:26:01.562377Z",
     "start_time": "2025-09-19T15:26:01.529700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number is probably accurate enough\n",
    "df_human.loc[:, 'CAI_score_global_CDS'] = 0.5752 # in frame =1\n",
    "# df_yeast.loc[:, 'CAI_score_global_CDS'] = 0.5590591814785562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a652dd4e63f0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:26:03.928465Z",
     "start_time": "2025-09-19T15:26:03.771909Z"
    }
   },
   "outputs": [],
   "source": [
    "df_human_scores = model.predict(df_human[selected_features])\n",
    "\n",
    "# Assuming you already have get_antisense(seq: str) -> str defined\n",
    "# get_antisense, for some reason numba doesn't work well\n",
    "tbl = str.maketrans(\"ACGTUacgtuNn\", \"TGCAAtgcaaNn\")\n",
    "\n",
    "df_human[\"score\"] = df_human_scores\n",
    "\n",
    "df_human[\"sense\"] = df_human[SEQUENCE].astype(str).str.translate(tbl).str[::-1]\n",
    "(\n",
    "    df_human.assign(score=df_human_scores)\n",
    "    .sort_values(\"score\", ascending=False)  # sort by score\n",
    "    .to_csv(\"df_human_scores_model2.csv\", index=False)\n",
    ")\n",
    "\n",
    "df_sorted = df_human.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd142e4e4cf7114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:13:38.471598Z",
     "start_time": "2025-09-19T15:26:29.541379Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install requests\n",
    "import math, time, threading, urllib.parse, requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "UA = {\"User-Agent\": \"python-requests gggenome/greedy\"}\n",
    "\n",
    "def _ggg_hits_leq_json(seq, k, db=\"hg38\", timeout=180, retries=2):\n",
    "    \"\"\"Count hits with <=k mismatches via GGGenome JSON; fallback to CSV if needed.\"\"\"\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    q = urllib.parse.quote(s)\n",
    "    url_json = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.json\"\n",
    "    url_csv  = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.csv?download\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url_json, headers=UA, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            try:\n",
    "                data = r.json()\n",
    "            except ValueError:\n",
    "                raise RuntimeError(\"JSON parse failed\")\n",
    "            if isinstance(data, list):\n",
    "                return len(data)\n",
    "            if isinstance(data, dict):\n",
    "                if \"results\" in data and isinstance(data[\"results\"], list): return len(data[\"results\"])\n",
    "                if \"hits\" in data and isinstance(data[\"hits\"], list):       return len(data[\"hits\"])\n",
    "                return sum(len(v) for v in data.values() if isinstance(v, list))\n",
    "            return 0\n",
    "        except Exception:\n",
    "            # greedy CSV fallback\n",
    "            try:\n",
    "                r2 = requests.get(url_csv, headers=UA, timeout=timeout)\n",
    "                r2.raise_for_status()\n",
    "                return sum(1 for ln in r2.text.splitlines() if ln and not ln.startswith(\"#\"))\n",
    "            except Exception:\n",
    "                if attempt < retries:\n",
    "                    continue\n",
    "                return 0\n",
    "    return 0\n",
    "\n",
    "def _d123_for_sequence(seq, db=\"hg38\"):\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    if not s:\n",
    "        return (s, 0, 0, 0)\n",
    "    L = len(s)\n",
    "    k_allowed = max(0, math.floor(0.25 * L))  # GGGenome cap\n",
    "    k0 = _ggg_hits_leq_json(s, 0, db=db)\n",
    "    k1 = _ggg_hits_leq_json(s, 1, db=db) if k_allowed >= 1 else 0\n",
    "    # k2 = _ggg_hits_leq_json(s, 2, db=db) if k_allowed >= 2 else 0\n",
    "    # k3 = _ggg_hits_leq_json(s, 3, db=db) if k_allowed >= 3 else 0\n",
    "    d1 = max(0, k1 - k0)\n",
    "    # d2 = max(0, k2 - k1)\n",
    "    # d3 = max(0, k3 - k2)\n",
    "    return (s, d1, 0, 0, k0)\n",
    "\n",
    "cache = {}\n",
    "def add_gggenome_d123(main_df, seq_col=\"SEQUENCE\", db=\"hg38\", *, max_workers=32, print_every=10):\n",
    "    seqs = (main_df[seq_col].astype(str).str.upper().str.replace(\"U\", \"T\", regex=False))\n",
    "    uniq = seqs.dropna().unique().tolist()\n",
    "    N = len(uniq)\n",
    "    print(f\"[GGG] Unique sequences: {N} | db={db} | workers={max_workers}\")\n",
    "\n",
    "    global cache\n",
    "    cache = {}\n",
    "    lock = threading.Lock()\n",
    "    t0 = time.perf_counter()\n",
    "    errs = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = {ex.submit(_d123_for_sequence, s, db): s for s in uniq}\n",
    "        done = 0\n",
    "        for fut in as_completed(futs):\n",
    "            s = futs[fut]\n",
    "            try:\n",
    "                s_key, d1, d2, d3, d0 = fut.result()\n",
    "            except Exception:\n",
    "                d0 = d1 = d2 = d3 = 0\n",
    "                with lock:\n",
    "                    errs += 1\n",
    "            with lock:\n",
    "                cache[s] = (s, d1, d2, d3, d0)\n",
    "                done += 1\n",
    "                if (done == 1) or (done % print_every == 0) or (done == N):\n",
    "                    elapsed = time.perf_counter() - t0\n",
    "                    rps = done / elapsed if elapsed > 0 else 0.0\n",
    "                    print(f\"[GGG] {done}/{N} cached | ~{rps:.1f} seq/s | errors={errs}\")\n",
    "\n",
    "    main_df[\"ggg_d1\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[1])\n",
    "    main_df[\"ggg_d0\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[4])\n",
    "    # main_df[\"ggg_d2\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[2])\n",
    "    # main_df[\"ggg_d3\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[3])\n",
    "\n",
    "\n",
    "    print(f\"[GGG] Finished in {time.perf_counter() - t0:.1f}s. Added columns: ggg_d1, ggg_d2, ggg_d3\")\n",
    "    return main_df\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "# main_df = main_df[main_df[SENSE_START] != -1]\n",
    "result = add_gggenome_d123(df_sorted[:500], seq_col='sense', db=\"hg38\", max_workers=1, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee31ec34c459c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:54:16.003053Z",
     "start_time": "2025-09-19T16:54:15.970581Z"
    }
   },
   "outputs": [],
   "source": [
    "result.insert(0, \"row_number\", range(1, len(result) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88061caa6f58f5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:54:16.740381Z",
     "start_time": "2025-09-19T16:54:16.702272Z"
    }
   },
   "outputs": [],
   "source": [
    "result[result['ggg_d0'] ==0].head(50)[[SEQUENCE, 'row_number', 'sense_start', 'ggg_d0', 'ggg_d1', 'RNaseH1_Krel_score_R7_krel', 'at_skew', 'gc_content', 'on_target_fold_openness_normalized40_15', 'sense_avg_accessibility']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799f4b0e28e87e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:10:23.998501Z",
     "start_time": "2025-09-19T15:10:23.973009Z"
    }
   },
   "outputs": [],
   "source": [
    "GFP_IN_HUMAN[633:633 + 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906307b2abbba28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:10:18.344557Z",
     "start_time": "2025-09-19T15:10:18.307275Z"
    }
   },
   "outputs": [],
   "source": [
    "GFP_IN_HUMAN[679 :679 + 16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7215e6341764f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T11:34:05.016943Z",
     "start_time": "2025-09-18T11:34:04.997694Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Insert row number (1,2,3,...)\n",
    "result = result.copy()\n",
    "# result.insert(0, \"row_number\", range(1, len(result) + 1))\n",
    "\n",
    "# 2. Filter on ggg_d1 < 50\n",
    "filtered = result[result[\"ggg_d1\"] < 500]\n",
    "\n",
    "# 3. Print selected columns\n",
    "print(filtered[[\n",
    "    \"row_number\", SEQUENCE, \"sense_start\", \"ggg_d1\", \"at_skew\", \"gc_content\",\n",
    "    \"on_target_fold_openness_normalized40_15\",\n",
    "    \"sense_avg_accessibility\", \"RNaseH1_Krel_score_R7_krel\"\n",
    "]].head(60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd981ffddb03542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T23:11:56.594883Z",
     "start_time": "2025-09-17T23:11:56.570294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Appendix for CAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325fee15269f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "# Yeast codon usage table (S. cerevisiae, from Codon Usage Database)\n",
    "# frequency per thousand, normalized to relative adaptiveness (w values)\n",
    "# For simplicity, store as preferred-codon relative adaptiveness\n",
    "yeast_codon_pref = {\n",
    "    'TTT':0.61,'TTC':1.0,'TTA':0.19,'TTG':0.45,'CTT':0.10,'CTC':0.08,'CTA':0.07,'CTG':0.09,\n",
    "    'ATT':0.36,'ATC':1.0,'ATA':0.12,'ATG':1.0,\n",
    "    'GTT':0.47,'GTC':0.15,'GTA':0.14,'GTG':0.25,\n",
    "    'TCT':0.55,'TCC':0.54,'TCA':0.37,'TCG':0.17,'AGT':0.39,'AGC':1.0,\n",
    "    'CCT':0.61,'CCC':0.21,'CCA':0.63,'CCG':0.15,\n",
    "    'ACT':0.60,'ACC':1.0,'ACA':0.36,'ACG':0.13,\n",
    "    'GCT':0.82,'GCC':0.49,'GCA':0.58,'GCG':0.13,\n",
    "    'TAT':0.57,'TAC':1.0,'TAA':0,'TAG':0,'TGA':0,\n",
    "    'CAT':0.57,'CAC':1.0,\n",
    "    'CAA':0.34,'CAG':1.0,\n",
    "    'AAT':0.53,'AAC':1.0,\n",
    "    'AAA':0.44,'AAG':1.0,\n",
    "    'GAT':0.46,'GAC':1.0,\n",
    "    'GAA':0.38,'GAG':1.0,\n",
    "    'TGT':0.44,'TGC':1.0,'TGG':1.0,\n",
    "    'CGT':0.56,'CGC':0.65,'CGA':0.14,'CGG':0.14,'AGA':0.05,'AGG':0.02,\n",
    "    'GGT':0.53,'GGC':0.49,'GGA':1.0,'GGG':0.27\n",
    "}\n",
    "\n",
    "# Input sequence (from user)\n",
    "seq = (\"ATGGTtAGtAAaGGaGAaGAGTTgTTCACaGGaGTGGTGCCCATCCTGGTCGAGCTGGACGGCGACGTAAACGGCCACAAGTTCAGCGTGTCCGGCGAGGGCGAGGGCGATGCCACCTACGGCAAGCTGACCCTGAAGTTCATCTGCACCACCGGCAAGCTGCCCGTGCCCTGGCCCACCCTCGTGACCACCCTGACCTACGGCGTGCAGTGCTTCAGCCGCTACCCCGACCACATGAAGCAGCACGACTTCTTCAAGTCCGCCATGCCCGAAGGCTACGTCCAGGAGCGCACCATCTTCTTCAAGGACGACGGCAACTACAAGACCCGCGCCGAGGTGAAGTTCGAGGGCGACACCCTGGTGAACCGCATCGAGCTGAAGGGCATCGACTTCAAGGAGGACGGCAACATCCTGGGGCACAAGCTGGAGTACAACTACAACAGCCACAACGTCTATATCATGGCCGACAAGCAGAAGAACGGCATCAAGGTGAACTTCAAGATCCGCCACAACATCGAGGACGGCAGCGTGCAGCTCGCCGACCACTACCAGCAGAACACCCCCATCGGCGACGGCCCCGTGCTGCTGCCCGACAACCACTACCTGAGCACCCAGTCCGCCCTGAGCAAAGACCCCAACGAGAAGCGCGATCACATGGTCCTGCTGGAGTTCGTGACCGCCGCCGGGATCACTCTCGGCATGGACGAGCTGTACAAGGGTGCTGGGGCAggtacCCCTAAAGATCCAGCCAAACCTCCGGCCAcGGCACAAGTTGTGGGATGGCCACCGGTGAGATCATACCGGAAGAACGTGATGGTTTCCTGCCAAAAATCAAGCGGTGGCCCGGAGGCGGCGGCGTTCGTGAAGTAA\").upper()\n",
    "\n",
    "# Split into codons\n",
    "codons = [seq[i:i+3] for i in range(0, len(seq), 3)]\n",
    "# Drop stop codon and any incomplete codons at the end\n",
    "valid_codons = [c for c in codons if c in yeast_codon_pref and yeast_codon_pref[c] > 0]\n",
    "\n",
    "# Calculate weights\n",
    "weights = [yeast_codon_pref[c] for c in valid_codons]\n",
    "\n",
    "# Compute CAI\n",
    "cai = prod(weights) ** (1/len(weights))\n",
    "cai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d620bc7716dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "# Human codon usage table (Homo sapiens, whole genome, from Kazusa)\n",
    "# Values are normalized as relative adaptiveness (w)\n",
    "# Frequencies per 1000 codons (rounded from Kazusa)\n",
    "human_freqs = {\n",
    "    'TTT':17.6,'TTC':20.3,'TTA':7.7,'TTG':12.9,'CTT':13.2,'CTC':19.6,'CTA':7.2,'CTG':39.6,\n",
    "    'ATT':16.0,'ATC':20.8,'ATA':7.5,'ATG':22.0,\n",
    "    'GTT':10.8,'GTC':14.6,'GTA':7.1,'GTG':28.1,\n",
    "    'TCT':15.2,'TCC':17.6,'TCA':12.2,'TCG':4.5,'AGT':11.9,'AGC':19.5,\n",
    "    'CCT':17.5,'CCC':19.8,'CCA':16.9,'CCG':6.9,\n",
    "    'ACT':13.1,'ACC':21.2,'ACA':15.1,'ACG':6.1,\n",
    "    'GCT':18.2,'GCC':27.7,'GCA':15.8,'GCG':7.4,\n",
    "    'TAT':12.0,'TAC':15.6,'TAA':1.0,'TAG':0.8,'TGA':1.6,\n",
    "    'CAT':10.9,'CAC':15.1,\n",
    "    'CAA':12.3,'CAG':34.2,\n",
    "    'AAT':17.0,'AAC':19.1,\n",
    "    'AAA':24.4,'AAG':32.5,\n",
    "    'GAT':22.3,'GAC':26.0,\n",
    "    'GAA':29.0,'GAG':39.6,\n",
    "    'TGT':10.8,'TGC':12.1,'TGG':13.2,\n",
    "    'CGT':4.7,'CGC':10.5,'CGA':6.2,'CGG':11.4,'AGA':12.1,'AGG':11.5,\n",
    "    'GGT':10.8,'GGC':22.2,'GGA':16.5,'GGG':16.5\n",
    "}\n",
    "\n",
    "# Normalize to get relative adaptiveness (w)\n",
    "human_w = {}\n",
    "for codon in human_freqs:\n",
    "    aa_group = [c for c in human_freqs if c[0] == codon[0] or True]  # lazy grouping\n",
    "# Let's just hard-code amino acid codon groupings\n",
    "aa_codons = {\n",
    "    'F':['TTT','TTC'],\n",
    "    'L':['TTA','TTG','CTT','CTC','CTA','CTG'],\n",
    "    'I':['ATT','ATC','ATA'],\n",
    "    'M':['ATG'],\n",
    "    'V':['GTT','GTC','GTA','GTG'],\n",
    "    'S':['TCT','TCC','TCA','TCG','AGT','AGC'],\n",
    "    'P':['CCT','CCC','CCA','CCG'],\n",
    "    'T':['ACT','ACC','ACA','ACG'],\n",
    "    'A':['GCT','GCC','GCA','GCG'],\n",
    "    'Y':['TAT','TAC'],\n",
    "    'H':['CAT','CAC'],\n",
    "    'Q':['CAA','CAG'],\n",
    "    'N':['AAT','AAC'],\n",
    "    'K':['AAA','AAG'],\n",
    "    'D':['GAT','GAC'],\n",
    "    'E':['GAA','GAG'],\n",
    "    'C':['TGT','TGC'],\n",
    "    'W':['TGG'],\n",
    "    'R':['CGT','CGC','CGA','CGG','AGA','AGG'],\n",
    "    'G':['GGT','GGC','GGA','GGG'],\n",
    "    'STOP':['TAA','TAG','TGA']\n",
    "}\n",
    "for aa, codon_list in aa_codons.items():\n",
    "    maxf = max(human_freqs[c] for c in codon_list)\n",
    "    for c in codon_list:\n",
    "        if human_freqs[c] > 0:\n",
    "            human_w[c] = human_freqs[c]/maxf\n",
    "        else:\n",
    "            human_w[c] = 0\n",
    "\n",
    "# Input sequence (human GFP variant)\n",
    "seq_human = (\"atggtgagcaagggcgaggagctgttcaccggggtggtgcccatcctggtcgagctggacggcgacgtaaacggccacaagttcagcgtgtccggcgagggcgagggcgatgccacctacggcaagctgaccctgaagttcatctgcaccaccggcaagctgcccgtgccctggcccaccctcgtgaccaccctgacctacggcgtgcagtgcttcagccgctaccccgaccacatgaagcagcacgacttcttcaagtccgccatgcccgaaggctacgtccaggagcgcaccatcttcttcaaggacgacggcaactacaagacccgcgccgaggtgaagttcgagggcgacaccctggtgaaccgcatcgagctgaagggcatcgacttcaaggaggacggcaacatcctggggcacaagctggagtacaactacaacagccacaacgtctatatcatggccgacaagcagaagaacggcatcaaggtgaacttcaagatccgccacaacatcgaggacggcagcgtgcagctcgccgaccactaccagcagaacacccccatcggcgacggccccgtgctgctgcccgacaaccactacctgagcacccagtccgccctgagcaaagaccccaacgagaagcgcgatcacatggtcctgctggagttcgtgaccgccgccgggatcactctcggcatggacgagctgtacaagaagcttagccatggcttcccgccggaggtggaggagcaggatgatggcacgctgcccatgtcttgtgcccaggagagcgggatggaccgtcaccctgcagcctgtgcttctgctaggatcaatgtgaagcgacctgccgccacaaagaaggctggacaggctaagaagaagaaatgaggatcccgcgcgcgcatatgttaattaaccaactgcatggggatccacgcgttaagtcgacaatcaacctctggattacaaaatttgtgaaagattgactggtattcttaactatgttgctccttttacgctatgtggatacgctgctttaatgcctttgtatcatgctattgcttcccgtatggctttcattttctcctccttgtataaatcctggttgctgtctctttatgaggagttgtggcccgttgtcaggcaacgtggcgtggtgtgcactgtgtttgctgacgcaacccccactggttggggcattgccaccacctgtcagctcctttccgggactttcgctttccccctccctattgccacggcggaactcatcgccgcctgccttgcccgctgctggacaggggctcggctgttgggcactgacaattccgtggtgttgtcggggaaatcatcgtcctttccttggctgctcgcctgtgttgccacctggattctgcgcgggacgtccttctgctacgtcccttcggccctcaatccagcggaccttccttcccgcggcctgctgccggctctgcggcctcttccgcgtcttcgccttcgccctcagacgagtcggatctccctttgggccgcctccccgcgtcgactttaagaccaatgacttacaaggcagctgtagatcttagccactttttaaaagaaaaggggggactggaagggctaattcactcccaacgaagacaagatctgctttttgcttgtactgggtctctctggttagaccagatctgagcctgggagctctctggctaactagggaacccactgcttaagcctcaataaagcttgccttgagtgcttcaagtagtgtgtgcccgtctgttgtgtgactctggtaactagagatccctcagacccttttagtcagtgtggaaaatctctagcagtacgtatagtagttcatgtcatcttattattcagtatttataacttgcaaagaaatgaatatcagagagtgagagg\")\n",
    "\n",
    "# Split into codons\n",
    "codons_h = [seq_human[i:i+3].upper() for i in range(0, len(seq_human), 3)]\n",
    "valid_codons_h = [c for c in codons_h if c in human_w and human_w[c] > 0]\n",
    "\n",
    "weights_h = [human_w[c] for c in valid_codons_h]\n",
    "cai_h = prod(weights_h) ** (1/len(weights_h))\n",
    "cai_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149866da08b270d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T21:30:18.563752Z",
     "start_time": "2025-09-20T21:29:41.848369Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.read_human_genome import get_locus_to_data_dict\n",
    "import pickle\n",
    "from asodesigner.consts import CACHE_DIR\n",
    "\n",
    "# Adding RB1 and TP53BP1\n",
    "genes_u = ['HIF1A', 'APOL1', 'YAP1', 'SOD1', 'SNCA', 'IRF4', 'KRAS', 'KLKB1', 'SNHG14', 'DGAT2', 'IRF5', 'HTRA1',\n",
    "           'MYH7', 'MALAT1', 'HSD17B13', 'PRMT5', 'MAT2A', 'RIOK1', 'RB1', 'TP53BP1']\n",
    "cache_path = CACHE_DIR / 'gene_to_data_simple_cache.pickle'\n",
    "# if not cache_path.exists():\n",
    "if True:\n",
    "    gene_to_data = get_locus_to_data_dict(include_introns=True, gene_subset=genes_u)\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump(gene_to_data, f)\n",
    "else:\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        gene_to_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18daa07a684735d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T21:30:52.305247Z",
     "start_time": "2025-09-20T21:30:52.246360Z"
    }
   },
   "outputs": [],
   "source": [
    "SL_PARTNERS = ['RB1', 'TP53BP1']\n",
    "SEQUENCES = {}\n",
    "for partner in SL_PARTNERS:\n",
    "    SEQUENCES[partner] = gene_to_data[partner].full_mrna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215841936ac4a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:07:38.710485Z",
     "start_time": "2025-09-22T12:07:35.901466Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "import pandas as pd\n",
    "\n",
    "# GFP_YEAST_END = len(GFP_IN_YEAST) - 3\n",
    "GFP_HUMAN_END = len(GFP_IN_HUMAN)\n",
    "LNA_SIZE = 16\n",
    "\n",
    "def get_init_df(target_mrna, end, aso_sizes=[LNA_SIZE]):\n",
    "    candidates = []\n",
    "    sense_starts = []\n",
    "    sense_lengths = []\n",
    "    sense_starts_from_end = []\n",
    "\n",
    "    for aso_size in aso_sizes:\n",
    "        for i in range(0, len(target_mrna) - (aso_size - 1)):\n",
    "            target = target_mrna[i: i + aso_size]\n",
    "            candidates.append(get_antisense(str(target)))\n",
    "            sense_starts.append(i)\n",
    "            sense_lengths.append(aso_size)\n",
    "            sense_starts_from_end.append(end - i)\n",
    "    df = pd.DataFrame(\n",
    "        {SEQUENCE: candidates, SENSE_START: sense_starts,\n",
    "         SENSE_LENGTH: sense_lengths, \"sense_start_from_end\": sense_starts_from_end})\n",
    "    return df\n",
    "\n",
    "dfs = dict()\n",
    "# df_yeast = get_init_df(GFP_IN_YEAST, GFP_YEAST_END)\n",
    "for partner in SL_PARTNERS:\n",
    "    dfs[partner] = get_init_df(gene_to_data[partner].full_mrna, len(gene_to_data[partner].full_mrna), aso_sizes=[16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385d6d8022cba57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:13:52.829837Z",
     "start_time": "2025-09-22T12:08:10.404487Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_genertion.data_handling import get_populated_df_with_structure_features\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    df[CELL_LINE_ORGANISM] = 'human'\n",
    "    df[INHIBITION] = 0\n",
    "    df[CANONICAL_GENE] = gene\n",
    "    df = get_populated_df_with_structure_features(df, genes_u, gene_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60576475f587199a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:17:37.440251Z",
     "start_time": "2025-09-22T12:15:47.390790Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_genertion.data_handling import populate_features\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    df[TREATMENT_PERIOD] = 24  # keep constant for all\n",
    "    df[VOLUME] = 1000  # keep constant for all\n",
    "    df['log_volume'] = np.log(df[VOLUME])\n",
    "    df['normalized_start'] = df[SENSE_START] / len(SEQUENCES[gene])\n",
    "    df['normalized_sense_start_from_end'] = df['sense_start_from_end'] / len(SEQUENCES[gene])\n",
    "    easy_to_populate = ['at_skew', 'gc_content', 'gc_content_3_prime_5', 'gc_skew', 'hairpin_score',\n",
    "                        'homooligo_count', 'internal_fold', 'nucleotide_diversity', 'self_energy', 'stop_codon_count',\n",
    "                        'at_rich_region_score', 'poly_pyrimidine_stretch']\n",
    "    populate_features(df, easy_to_populate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3ceaa97e12b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:17:44.560470Z",
     "start_time": "2025-09-22T12:17:44.520633Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_populate_fold(df, genes_u, gene_to_data, fold_variants=[(40, 15)]):\n",
    "    from asodesigner.fold import calculate_energies, get_weighted_energy\n",
    "    from asodesigner.util import get_antisense\n",
    "\n",
    "    all_data_human_gene_premrna_no_nan = df.copy()\n",
    "\n",
    "    # Comment out the long cases for quick running\n",
    "    for (window_size, step_size) in fold_variants:\n",
    "\n",
    "        on_target_fold = 'on_target_fold_openness' + str(window_size) + '_' + str(step_size)\n",
    "        on_target_fold_normalized = 'on_target_fold_openness_normalized' + str(window_size) + '_' + str(step_size)\n",
    "        all_data_human_gene_premrna_no_nan[on_target_fold] = np.zeros_like(all_data_human_gene_premrna_no_nan[SEQUENCE],\n",
    "                                                                           dtype=np.float64)\n",
    "        all_data_human_gene_premrna_no_nan[on_target_fold_normalized] = np.zeros_like(\n",
    "            all_data_human_gene_premrna_no_nan[SEQUENCE], dtype=np.float64)\n",
    "\n",
    "        for gene in genes_u:\n",
    "\n",
    "            target = gene_to_data[gene].full_mrna\n",
    "            gene_rows = all_data_human_gene_premrna_no_nan[all_data_human_gene_premrna_no_nan[CANONICAL_GENE] == gene]\n",
    "            energies = calculate_energies(str(target), step_size, window_size)\n",
    "\n",
    "            for index, row in gene_rows.iterrows():\n",
    "                antisense = row[SEQUENCE]\n",
    "                sense = get_antisense(antisense)\n",
    "                l = row[SENSE_LENGTH]\n",
    "                sense_start = row[SENSE_START]\n",
    "                mean_fold = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                mean_fold_end = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                mean_fold_start = get_weighted_energy(sense_start, l, step_size, energies, window_size)\n",
    "                if mean_fold > 100:\n",
    "                    print(energies)\n",
    "                    print(\"Weird: \", mean_fold)\n",
    "                    print(\"Sense_start \", sense_start)\n",
    "                    print(\"Sense_length \", l)\n",
    "                    print(\"Gene: \", gene)\n",
    "                    mean_fold = 0\n",
    "                all_data_human_gene_premrna_no_nan.loc[index, on_target_fold] = mean_fold\n",
    "                all_data_human_gene_premrna_no_nan.loc[index, on_target_fold_normalized] = mean_fold / l\n",
    "    return all_data_human_gene_premrna_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe794d27de82ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:21:40.462760Z",
     "start_time": "2025-09-22T12:17:50.956046Z"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_genertion.data_handling import get_populate_fold\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    fold_variants = [(40, 15)]\n",
    "    df = get_populate_fold(df, SL_PARTNERS, gene_to_data, fold_variants=fold_variants)\n",
    "    dfs[gene] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9f13c999b6faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:21:59.403451Z",
     "start_time": "2025-09-22T12:21:58.033924Z"
    }
   },
   "outputs": [],
   "source": [
    "from hybridization.hybridization_features import get_exp_psrna_hybridization\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    df.loc[:, 'exp_ps_hybr'] = [\n",
    "        get_exp_psrna_hybridization(antisense.replace('T', 'U'), temp=37) for\n",
    "        antisense in df[SEQUENCE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7883bf3d970ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:22:04.345342Z",
     "start_time": "2025-09-22T12:22:04.028266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missing: CAI_score_global_CDS, 'sense_avg_accessibility', RNaseH1_Krel_score_R7_krel, Modification_min_distance_to_3prime\n",
    "from features.mod_features import compute_mod_min_distance_to_3prime\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    if df[SEQUENCE].str.len().eq(20).any():\n",
    "        df.loc[df[SEQUENCE].str.len() == 20, \"Modification_min_distance_to_3prime\"] = \\\n",
    "            compute_mod_min_distance_to_3prime(\"MMMMMddddddddddMMMMM\")\n",
    "\n",
    "    if df[SEQUENCE].str.len().eq(16).any():\n",
    "        df.loc[df[SEQUENCE].str.len() == 16, \"Modification_min_distance_to_3prime\"] = \\\n",
    "            compute_mod_min_distance_to_3prime(\"LLLddddddddddLLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147c8d659c859a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T16:27:34.407519Z",
     "start_time": "2025-09-20T22:11:18.036755Z"
    }
   },
   "outputs": [],
   "source": [
    "from yehuda_code.Folding_Functions import get_sense_with_flanks\n",
    "from yehuda_code.access_calculator import AccessCalculator\n",
    "\n",
    "FLANK_SIZE = 120\n",
    "ACCESS_SIZE = 13\n",
    "SEED_SIZE = 13\n",
    "SEED_SIZES = [SEED_SIZE * m for m in range(1, 4)]\n",
    "ACCESS_WIN_SIZE = 80\n",
    "\n",
    "def compute_sense_accessibility(row, flank_size, access_win_size, seed_sizes, access_size, min_gc=0, max_gc=100,\n",
    "                                gc_ranges=1):\n",
    "    try:\n",
    "        # Skip invalid rows\n",
    "        if row['sense_start'] == -1 or pd.isna(row['sense_with_flank_120nt']) or row['sense_with_flank_120nt'] == \"\":\n",
    "            return None\n",
    "\n",
    "        seq = row[f'sense_with_flank_{flank_size}nt']\n",
    "        sense_start = row['sense_start']\n",
    "        sense_length = row['sense_length']\n",
    "\n",
    "        # Calculate accessibility\n",
    "        df_access = AccessCalculator.calc(\n",
    "            seq, access_size,\n",
    "            min_gc, max_gc, gc_ranges,\n",
    "            access_win_size, seed_sizes\n",
    "        )\n",
    "\n",
    "        flank_start = max(0, sense_start - flank_size)\n",
    "        sense_start_in_flank = sense_start - flank_start\n",
    "        sense_end_in_flank = sense_start_in_flank + sense_length\n",
    "\n",
    "        if 0 <= sense_start_in_flank < len(df_access) and sense_end_in_flank <= len(df_access):\n",
    "            values = df_access['avg_access'].iloc[sense_start_in_flank:sense_end_in_flank].dropna()\n",
    "            return values.mean() if not values.empty else None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {row.name} | seq start: {row['sense_start']} | error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "for gene, df in dfs.items():\n",
    "    FLANKED_SENSE_COL = f'sense_with_flank_{FLANK_SIZE}nt'\n",
    "\n",
    "    val = gene_to_data[gene].full_mrna\n",
    "    df['pre_mrna_sequence'] = [val] * len(df)\n",
    "\n",
    "    # Create new column with flanked sequences\n",
    "    df[FLANKED_SENSE_COL] = df.apply(\n",
    "        lambda row: get_sense_with_flanks(\n",
    "            row['pre_mrna_sequence'],\n",
    "            row['sense_start'],\n",
    "            row['sense_length'],\n",
    "            flank_size=FLANK_SIZE\n",
    "        ) if row['sense_start'] != -1 else \"\",  # Handle cases where sense was not found\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    batch_size = 500\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "        print(f\"Processing rows {start_idx} to {end_idx}...\")\n",
    "\n",
    "        batch['sense_avg_accessibility'] = batch.apply(\n",
    "            compute_sense_accessibility,\n",
    "            axis=1,\n",
    "            flank_size=FLANK_SIZE,\n",
    "            access_win_size=ACCESS_WIN_SIZE,\n",
    "            seed_sizes=SEED_SIZES,\n",
    "            access_size=ACCESS_SIZE,\n",
    "        )\n",
    "\n",
    "        # Save batch to the new folder\n",
    "        batch.to_csv(f\"out/{gene}/batch_{start_idx}_{end_idx}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8665848bf67f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:26:12.620818Z",
     "start_time": "2025-09-22T12:22:34.949372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = sorted(glob.glob(f\"out/RB1/batch_*.csv\"))\n",
    "df_rb1_accessibility = pd.concat([pd.read_csv(f) for f in files], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c847b60ca861f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:29:12.050918Z",
     "start_time": "2025-09-22T12:29:11.811154Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rb1 = df_rb1_accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdfca68b39b8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:29:45.434999Z",
     "start_time": "2025-09-22T12:29:14.243162Z"
    }
   },
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(f\"out/TP53BP1/batch_*.csv\"))\n",
    "df_tp53bp1_accessibility = pd.concat([pd.read_csv(f) for f in files], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277e27efcf545b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:29:45.465391Z",
     "start_time": "2025-09-22T12:29:45.438909Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tp53bp1 = df_tp53bp1_accessibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce64c510a834aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:36:20.054682Z",
     "start_time": "2025-09-22T12:30:09.492213Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.features.RNaseH_features import rnaseh1_dict, compute_rnaseh1_score\n",
    "\n",
    "best_window_start_krel = {\n",
    "    'R4a_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 3, 18: 2, 19: 4, 20: 3, 21: 0, 22: 0, 25: 0},\n",
    "    'R4b_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 1, 18: 3, 19: 1, 20: 3, 21: 0, 22: 0, 25: 0},\n",
    "    'R7_krel': {10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 3, 17: 2, 18: 4, 19: 6, 20: 4, 21: 0, 22: 0, 25: 0},\n",
    "}\n",
    "\n",
    "for exp in ['R4a_krel', 'R4b_krel', 'R7_krel']:\n",
    "    weights = rnaseh1_dict(exp)\n",
    "\n",
    "    def score_row(row):\n",
    "        length = len(row['Sequence'])\n",
    "        pos = best_window_start_krel.get(exp, {}).get(length, 0)\n",
    "        return compute_rnaseh1_score(row['Sequence'], weights, window_start=pos)\n",
    "\n",
    "\n",
    "    col_name = f\"RNaseH1_Krel_score_{exp}\"\n",
    "\n",
    "    # Yeast should have similar motifs, perhaps\n",
    "    df_rb1[col_name] = df_rb1.apply(score_row, axis=1)\n",
    "    df_tp53bp1[col_name] = df_tp53bp1.apply(score_row, axis=1)\n",
    "\n",
    "RNaseH1_Krel_features_best = [f\"RNaseH1_Krel_score_{exp}\" for exp in ['R4a_krel', 'R4b_krel', 'R7_krel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aace29d8746068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:36:50.125398Z",
     "start_time": "2025-09-22T12:36:49.761812Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rb1_bak = df_rb1.copy()\n",
    "df_tp53bp1_bak = df_tp53bp1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64526c04e19fdedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:36:54.144115Z",
     "start_time": "2025-09-22T12:36:54.102789Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# External mRNA integration\n",
    "# =========================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def _norm_rna_to_dna(seq: str) -> str:\n",
    "    \"\"\"Normalize RNA to DNA alphabet (U->T), uppercase, strip whitespace.\"\"\"\n",
    "    return str(seq).upper().replace('U', 'T').replace(' ', '').replace('\\t', '').replace('\\n', '')\n",
    "\n",
    "\n",
    "def load_mrna_by_gene_from_files(files: list[str | Path],seq_column: str = \"Original Transcript Sequence\" ) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load {Gene -> <seq_column>} from a manual list of CSV paths.\n",
    "    - Expects columns: 'Gene' and <seq_column>\n",
    "    - Returns DNA alphabet (A/C/G/T) after U->T via _norm_rna_to_dna\n",
    "    - If multiple rows per gene: keeps the *longest* sequence\n",
    "    \"\"\"\n",
    "    files = [Path(f) for f in files]\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, usecols=['Gene', seq_column])\n",
    "        df[seq_column] = df[seq_column].map(_norm_rna_to_dna)\n",
    "        # Keep only clean sequences\n",
    "        df = df[df[seq_column].str.fullmatch(r'[ACGT]+', na=False)]\n",
    "        rows.append(df)\n",
    "\n",
    "    if not rows:\n",
    "        return {}\n",
    "\n",
    "    big = pd.concat(rows, ignore_index=True)\n",
    "    big['len'] = big[seq_column].str.len()\n",
    "    # Pick longest per gene\n",
    "    chosen = big.sort_values(['Gene', 'len'], ascending=[True, False]).drop_duplicates('Gene')\n",
    "    return dict(zip(chosen['Gene'], chosen[seq_column]))\n",
    "\n",
    "# ---- Choose which mRNA to use for mRNA-based features (tAI/windows on mRNA, etc.) ----\n",
    "def choose_preferred_mrna(gene_name: str, mrna_built_from_exons: str, gene_to_mrna_real: dict[str,str]) -> str:\n",
    "    \"\"\"\n",
    "    Prefer the real (external) mRNA when available; otherwise fall back to exon-joined.\n",
    "    Does NOT touch your genome->(mRNA/CDS) mappings or pre-mRNA flanks.\n",
    "    \"\"\"\n",
    "    ext = gene_to_mrna_real.get(gene_name)\n",
    "    return ext if ext else mrna_built_from_exons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b172b412016bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:36:56.432490Z",
     "start_time": "2025-09-22T12:36:56.404385Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from asodesigner.consts import *\n",
    "\n",
    "DATA_mRNA_PATH = PROJECT_PATH / \"scripts\" / \"data_genertion\" / \"cell_line_expression\"\n",
    "\n",
    "FILENAMES = [\n",
    "    \"ACH-000232_transcriptome.csv\",\n",
    "    \"ACH-000463_transcriptome.csv\",\n",
    "    \"ACH-000739_transcriptome.csv\",\n",
    "    \"ACH-001086_transcriptome.csv\",\n",
    "    \"ACH-001188_transcriptome.csv\",\n",
    "    \"ACH-001328_transcriptome.csv\",\n",
    "]\n",
    "\n",
    "EXTERNAL_MRNA_FILES = [DATA_mRNA_PATH / fn for fn in FILENAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a06aae74f3d76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:36:59.340328Z",
     "start_time": "2025-09-22T12:36:56.764628Z"
    }
   },
   "outputs": [],
   "source": [
    "d_orig = load_mrna_by_gene_from_files(\n",
    "    [str(p) for p in EXTERNAL_MRNA_FILES],\n",
    "    seq_column=\"Original Transcript sequence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d8a35bed386dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:37:04.117950Z",
     "start_time": "2025-09-22T12:36:59.343560Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(DATA_mRNA_PATH / \"ACH-000232_transcriptome.csv\")\n",
    "df2 = pd.read_csv(DATA_mRNA_PATH / \"ACH-000463_transcriptome.csv\")\n",
    "df3 = pd.read_csv(DATA_mRNA_PATH / \"ACH-000739_transcriptome.csv\")\n",
    "df4 = pd.read_csv(DATA_mRNA_PATH / \"ACH-001086_transcriptome.csv\")\n",
    "df5 = pd.read_csv(DATA_mRNA_PATH / \"ACH-001188_transcriptome.csv\")\n",
    "df6 = pd.read_csv(DATA_mRNA_PATH / \"ACH-001328_transcriptome.csv\")\n",
    "transcript_df = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)\n",
    "transcript_df = transcript_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ea8b0bc66b945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:37:05.773182Z",
     "start_time": "2025-09-22T12:37:05.728465Z"
    }
   },
   "outputs": [],
   "source": [
    "transcript_df = transcript_df.copy()\n",
    "\n",
    "transcript_df.loc[:, \"ref sequence\"] = (transcript_df[\"Mutated Transcript sequence\"].fillna(transcript_df[\"Original Transcript sequence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e5b7c4caa88b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:37:11.272549Z",
     "start_time": "2025-09-22T12:37:11.205185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build CAI reference weights directly from top-N transcript sequences (no CDS extraction)\n",
    "\n",
    "from asodesigner.features.cai import calc_CAI_weight  # make sure cai.py is importable\n",
    "\n",
    "TOP_N   = 300\n",
    "SEQ_COL = \"ref sequence\"\n",
    "EXPR_COL = \"expression_norm\"\n",
    "\n",
    "# Basic checks\n",
    "assert EXPR_COL in transcript_df.columns, f\"Missing '{EXPR_COL}' column\"\n",
    "assert SEQ_COL  in transcript_df.columns, f\"Missing '{SEQ_COL}' column\"\n",
    "\n",
    "# 1) Pick top-N by expression_norm\n",
    "ref_df = transcript_df.sort_values(EXPR_COL, ascending=False).head(TOP_N).copy()\n",
    "\n",
    "# 2) Take their sequences as-is (mRNA with U's; calc_CAI_weight handles U->T internally)\n",
    "reference_seqs = ref_df[SEQ_COL].dropna().astype(str).tolist()\n",
    "\n",
    "# 3) Build CAI weights\n",
    "weights_list, weights_flat = calc_CAI_weight(reference_seqs)\n",
    "\n",
    "print(f\"Built CAI weights from {len(reference_seqs)} transcript sequences (top {TOP_N} by {EXPR_COL}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ab694cf62aff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T07:11:22.795034Z",
     "start_time": "2025-09-22T07:11:22.081541Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rb1_bak = df_rb1.copy()\n",
    "df_tp53bp1_bak = df_tp53bp1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b323f10029cde4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:37:29.447877Z",
     "start_time": "2025-09-22T12:37:26.684766Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_mRNA_PATH = PROJECT_PATH / \"scripts\" / \"data_genertion\" / \"cell_line_expression\"\n",
    "\n",
    "FILENAMES = [\n",
    "    \"ACH-000232_transcriptome.csv\",\n",
    "    \"ACH-000463_transcriptome.csv\",\n",
    "    \"ACH-000739_transcriptome.csv\",\n",
    "    \"ACH-001086_transcriptome.csv\",\n",
    "    \"ACH-001188_transcriptome.csv\",\n",
    "    \"ACH-001328_transcriptome.csv\",\n",
    "]\n",
    "\n",
    "EXTERNAL_MRNA_FILES = [DATA_mRNA_PATH / fn for fn in FILENAMES]\n",
    "missing = [p.name for p in EXTERNAL_MRNA_FILES if not p.exists()]\n",
    "assert not missing, f\"Missing files in {DATA_mRNA_PATH}: {missing}\"\n",
    "\n",
    "# 1) Load Original\n",
    "try:\n",
    "    d_orig = load_mrna_by_gene_from_files(\n",
    "        [str(p) for p in EXTERNAL_MRNA_FILES],\n",
    "        seq_column=\"Original Transcript sequence\"\n",
    "    )\n",
    "except ValueError:\n",
    "    # in case the S is capitalized in your headers\n",
    "    d_orig = load_mrna_by_gene_from_files(\n",
    "        [str(p) for p in EXTERNAL_MRNA_FILES],\n",
    "        seq_column=\"Original Transcript Sequence\"\n",
    "    )\n",
    "\n",
    "# 2) Load Mutated\n",
    "try:\n",
    "    d_mut = load_mrna_by_gene_from_files(\n",
    "        [str(p) for p in EXTERNAL_MRNA_FILES],\n",
    "        seq_column=\"Mutated Transcript sequence\"\n",
    "    )\n",
    "except ValueError:\n",
    "    d_mut = load_mrna_by_gene_from_files(\n",
    "        [str(p) for p in EXTERNAL_MRNA_FILES],\n",
    "        seq_column=\"Mutated Transcript Sequence\"\n",
    "    )\n",
    "\n",
    "# 3) Prefer Mutated when available\n",
    "gene_to_mrna_real = {**d_orig, **d_mut}\n",
    "\n",
    "print(f\"Loaded {len(gene_to_mrna_real)} real mRNA sequences (Gene -> mRNA).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97175a0ad70b9d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:29:01.008559Z",
     "start_time": "2025-09-22T13:03:40.442547Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "import numpy as np\n",
    "\n",
    "# Column names\n",
    "SENSE_LENGTH      = 'sense_length'         # Length of the ASO (nt)\n",
    "SENSE_TYPE        = 'sense_type'           # exon / intron\n",
    "CDS_SEQUENCE      = 'cds_sequence'         # CDS string (joined exons within CDS range)\n",
    "IN_CODING_REGION  = 'in_coding_region'     # site is within CDS on a real exon\n",
    "\n",
    "# Flank sizes\n",
    "FLANK_SIZES_PREMRNA = [20, 30, 40, 50, 60, 70]\n",
    "FLANK_SIZES_CDS     = [20, 30, 40, 50, 60, 70]\n",
    "\n",
    "df_rb1[CDS_SEQUENCE]     = \"\"\n",
    "df_rb1[IN_CODING_REGION] = False\n",
    "\n",
    "for fs in FLANK_SIZES_PREMRNA:\n",
    "    df_rb1[f\"flank_sequence_{fs}\"] = \"\"\n",
    "for fs in FLANK_SIZES_CDS:\n",
    "    df_rb1[f\"local_coding_region_around_ASO_{fs}\"] = \"\"\n",
    "\n",
    "# ---- helpers (local to Part B) ----\n",
    "def _to_str_seq(x) -> str:\n",
    "    \"\"\"\n",
    "    Coerce sequence-like (list/np.array/Series) or string to a clean uppercase DNA string.\n",
    "    Converts U->T and strips whitespace. Ensures slicing returns a plain string (avoids pandas iterable assignment).\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        s = x\n",
    "    else:\n",
    "        try:\n",
    "            s = ''.join(list(x))\n",
    "        except Exception:\n",
    "            s = str(x)\n",
    "    return s.replace(' ', '').replace('\\t', '').replace('\\n', '').replace('U', 'T').upper()\n",
    "\n",
    "def _build_spliced_mrna_from_exons(pre_mrna: str, exon_indices):\n",
    "    \"\"\"\n",
    "    Build exon-joined mRNA by concatenating exon slices out of pre_mrna.\n",
    "    Keeps your original assumptions: pre_mrna corresponds to genomic strand and\n",
    "    starts at exon_indices[0][0]; exon intervals are used directly.\n",
    "    \"\"\"\n",
    "    if not exon_indices:\n",
    "        return \"\"\n",
    "    pre_genome_start = exon_indices[0][0]\n",
    "    parts = []\n",
    "    for exon_start, exon_end in exon_indices:\n",
    "        pm_start = exon_start - pre_genome_start\n",
    "        pm_end   = exon_end   - pre_genome_start\n",
    "        parts.append(pre_mrna[pm_start:pm_end])\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# Cache CDS per gene\n",
    "gene_to_cds_info = {}\n",
    "\n",
    "# ---- main loop ----\n",
    "for index, row in df_rb1.iterrows():\n",
    "    gene_name  = row[CANONICAL_GENE]\n",
    "    locus_info = gene_to_data[gene_name]\n",
    "\n",
    "    # Keep using your current pre-mRNA for flanks/exon-intron logic (coerced to clean string)\n",
    "    pre_mrna  = _to_str_seq(locus_info.full_mrna)\n",
    "    antisense = _to_str_seq(row[SEQUENCE])\n",
    "    sense     = _to_str_seq(get_antisense(antisense))\n",
    "\n",
    "    # Locate site on pre-mRNA\n",
    "    idx = pre_mrna.find(sense)\n",
    "    df_rb1.at[index, SENSE_LENGTH] = len(antisense)\n",
    "\n",
    "    if idx != -1:\n",
    "        # Genomic correction (kept as-is)\n",
    "        genome_corrected_index = idx + locus_info.exon_indices[0][0]\n",
    "\n",
    "        # pre-mRNA flanks (now using .at and guaranteed string slices)\n",
    "        for fs in FLANK_SIZES_PREMRNA:\n",
    "            flank_start = max(0, idx - fs)\n",
    "            flank_end   = min(len(pre_mrna), idx + len(sense) + fs)\n",
    "            flank_seq   = pre_mrna[flank_start:flank_end]\n",
    "            df_rb1.at[index, f\"flank_sequence_{fs}\"] = flank_seq\n",
    "\n",
    "        # Build CDS + genome->mRNA map (kept identical to your approach)\n",
    "        if gene_name not in gene_to_cds_info:\n",
    "            cds_seq = []  # build as list for speed, join at end\n",
    "            genome_to_mrna_map = {}\n",
    "            mrna_idx = 0\n",
    "            for exon_start, exon_end in locus_info.exon_indices:\n",
    "                for gpos in range(exon_start, exon_end):\n",
    "                    if mrna_idx >= len(pre_mrna):\n",
    "                        break\n",
    "                    if locus_info.cds_start <= gpos <= locus_info.cds_end:\n",
    "                        cds_seq.append(pre_mrna[mrna_idx])\n",
    "                        genome_to_mrna_map[gpos] = len(cds_seq) - 1\n",
    "                    mrna_idx += 1\n",
    "            cds_seq = ''.join(cds_seq)\n",
    "            gene_to_cds_info[gene_name] = (cds_seq, genome_to_mrna_map)\n",
    "        else:\n",
    "            cds_seq, genome_to_mrna_map = gene_to_cds_info[gene_name]\n",
    "\n",
    "        # Save CDS\n",
    "        df_rb1.at[index, CDS_SEQUENCE] = _to_str_seq(cds_seq)\n",
    "\n",
    "        #  NEW: prefer real mRNA for mRNA-based features (fallback to exon-joined)\n",
    "        mrna_built        = _build_spliced_mrna_from_exons(pre_mrna, locus_info.exon_indices)\n",
    "        mrna_for_features = choose_preferred_mrna(gene_name, mrna_built, gene_to_mrna_real)\n",
    "\n",
    "        # If within CDS, extract local CDS context (unchanged logic; .at + str)\n",
    "        if (\n",
    "            locus_info.cds_start <= genome_corrected_index <= locus_info.cds_end\n",
    "            and genome_corrected_index in genome_to_mrna_map\n",
    "        ):\n",
    "            df_rb1.at[index, IN_CODING_REGION] = True\n",
    "            cds_idx = genome_to_mrna_map[genome_corrected_index]\n",
    "            for fs in FLANK_SIZES_CDS:\n",
    "                start = max(0, cds_idx - fs)\n",
    "                end   = min(len(cds_seq), cds_idx + len(sense) + fs)\n",
    "                local_seq = cds_seq[start:end]\n",
    "                df_rb1.at[index, f\"local_coding_region_around_ASO_{fs}\"] = _to_str_seq(local_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badbb2625a87b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:43:12.789198Z",
     "start_time": "2025-09-22T12:38:38.042207Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "import numpy as np\n",
    "\n",
    "# Column names\n",
    "SENSE_LENGTH      = 'sense_length'         # Length of the ASO (nt)\n",
    "SENSE_TYPE        = 'sense_type'           # exon / intron\n",
    "CDS_SEQUENCE      = 'cds_sequence'         # CDS string (joined exons within CDS range)\n",
    "IN_CODING_REGION  = 'in_coding_region'     # site is within CDS on a real exon\n",
    "\n",
    "# Flank sizes\n",
    "FLANK_SIZES_PREMRNA = [20, 30, 40, 50, 60, 70]\n",
    "FLANK_SIZES_CDS     = [20, 30, 40, 50, 60, 70]\n",
    "\n",
    "df_tp53bp1[CDS_SEQUENCE]     = \"\"\n",
    "df_tp53bp1[IN_CODING_REGION] = False\n",
    "\n",
    "for fs in FLANK_SIZES_PREMRNA:\n",
    "    df_tp53bp1[f\"flank_sequence_{fs}\"] = \"\"\n",
    "for fs in FLANK_SIZES_CDS:\n",
    "    df_tp53bp1[f\"local_coding_region_around_ASO_{fs}\"] = \"\"\n",
    "\n",
    "# ---- helpers (local to Part B) ----\n",
    "def _to_str_seq(x) -> str:\n",
    "    \"\"\"\n",
    "    Coerce sequence-like (list/np.array/Series) or string to a clean uppercase DNA string.\n",
    "    Converts U->T and strips whitespace. Ensures slicing returns a plain string (avoids pandas iterable assignment).\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        s = x\n",
    "    else:\n",
    "        try:\n",
    "            s = ''.join(list(x))\n",
    "        except Exception:\n",
    "            s = str(x)\n",
    "    return s.replace(' ', '').replace('\\t', '').replace('\\n', '').replace('U', 'T').upper()\n",
    "\n",
    "def _build_spliced_mrna_from_exons(pre_mrna: str, exon_indices):\n",
    "    \"\"\"\n",
    "    Build exon-joined mRNA by concatenating exon slices out of pre_mrna.\n",
    "    Keeps your original assumptions: pre_mrna corresponds to genomic strand and\n",
    "    starts at exon_indices[0][0]; exon intervals are used directly.\n",
    "    \"\"\"\n",
    "    if not exon_indices:\n",
    "        return \"\"\n",
    "    pre_genome_start = exon_indices[0][0]\n",
    "    parts = []\n",
    "    for exon_start, exon_end in exon_indices:\n",
    "        pm_start = exon_start - pre_genome_start\n",
    "        pm_end   = exon_end   - pre_genome_start\n",
    "        parts.append(pre_mrna[pm_start:pm_end])\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# Cache CDS per gene\n",
    "gene_to_cds_info = {}\n",
    "\n",
    "# ---- main loop ----\n",
    "for index, row in df_tp53bp1.iterrows():\n",
    "    gene_name  = row[CANONICAL_GENE]\n",
    "    locus_info = gene_to_data[gene_name]\n",
    "\n",
    "    # Keep using your current pre-mRNA for flanks/exon-intron logic (coerced to clean string)\n",
    "    pre_mrna  = _to_str_seq(locus_info.full_mrna)\n",
    "    antisense = _to_str_seq(row[SEQUENCE])\n",
    "    sense     = _to_str_seq(get_antisense(antisense))\n",
    "\n",
    "    # Locate site on pre-mRNA\n",
    "    idx = pre_mrna.find(sense)\n",
    "    df_tp53bp1.at[index, SENSE_LENGTH] = len(antisense)\n",
    "\n",
    "    if idx != -1:\n",
    "        # Genomic correction (kept as-is)\n",
    "        genome_corrected_index = idx + locus_info.exon_indices[0][0]\n",
    "\n",
    "        # pre-mRNA flanks (now using .at and guaranteed string slices)\n",
    "        for fs in FLANK_SIZES_PREMRNA:\n",
    "            flank_start = max(0, idx - fs)\n",
    "            flank_end   = min(len(pre_mrna), idx + len(sense) + fs)\n",
    "            flank_seq   = pre_mrna[flank_start:flank_end]\n",
    "            df_tp53bp1.at[index, f\"flank_sequence_{fs}\"] = flank_seq\n",
    "\n",
    "        # Build CDS + genome->mRNA map (kept identical to your approach)\n",
    "        if gene_name not in gene_to_cds_info:\n",
    "            cds_seq = []  # build as list for speed, join at end\n",
    "            genome_to_mrna_map = {}\n",
    "            mrna_idx = 0\n",
    "            for exon_start, exon_end in locus_info.exon_indices:\n",
    "                for gpos in range(exon_start, exon_end):\n",
    "                    if mrna_idx >= len(pre_mrna):\n",
    "                        break\n",
    "                    if locus_info.cds_start <= gpos <= locus_info.cds_end:\n",
    "                        cds_seq.append(pre_mrna[mrna_idx])\n",
    "                        genome_to_mrna_map[gpos] = len(cds_seq) - 1\n",
    "                    mrna_idx += 1\n",
    "            cds_seq = ''.join(cds_seq)\n",
    "            gene_to_cds_info[gene_name] = (cds_seq, genome_to_mrna_map)\n",
    "        else:\n",
    "            cds_seq, genome_to_mrna_map = gene_to_cds_info[gene_name]\n",
    "\n",
    "        # Save CDS\n",
    "        df_tp53bp1.at[index, CDS_SEQUENCE] = _to_str_seq(cds_seq)\n",
    "\n",
    "        #  NEW: prefer real mRNA for mRNA-based features (fallback to exon-joined)\n",
    "        mrna_built        = _build_spliced_mrna_from_exons(pre_mrna, locus_info.exon_indices)\n",
    "        mrna_for_features = choose_preferred_mrna(gene_name, mrna_built, gene_to_mrna_real)\n",
    "\n",
    "        # If within CDS, extract local CDS context (unchanged logic; .at + str)\n",
    "        if (\n",
    "            locus_info.cds_start <= genome_corrected_index <= locus_info.cds_end\n",
    "            and genome_corrected_index in genome_to_mrna_map\n",
    "        ):\n",
    "            df_tp53bp1.at[index, IN_CODING_REGION] = True\n",
    "            cds_idx = genome_to_mrna_map[genome_corrected_index]\n",
    "            for fs in FLANK_SIZES_CDS:\n",
    "                start = max(0, cds_idx - fs)\n",
    "                end   = min(len(cds_seq), cds_idx + len(sense) + fs)\n",
    "                local_seq = cds_seq[start:end]\n",
    "                df_tp53bp1.at[index, f\"local_coding_region_around_ASO_{fs}\"] = _to_str_seq(local_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8718c4388c533d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:03:36.271246Z",
     "start_time": "2025-09-22T13:03:36.224309Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tp53bp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621a93a7f60424f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:29:26.015419Z",
     "start_time": "2025-09-22T13:29:25.796756Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define flank sizes\n",
    "CDS_WINDOWS = FLANK_SIZES_CDS\n",
    "\n",
    "# Loop over each flank window size\n",
    "for flank in CDS_WINDOWS:\n",
    "    local_col = f\"local_coding_region_around_ASO_{flank}\"\n",
    "    is_local_flag_col = f\"region_is_local_{flank}\"\n",
    "\n",
    "    # Create the binary flag: 1 if local exists, 0 otherwise\n",
    "    df_tp53bp1[is_local_flag_col] = df_tp53bp1[local_col].apply(\n",
    "        lambda x: isinstance(x, str) and x.strip() != \"\"\n",
    "    ).astype(int)\n",
    "\n",
    "    # Create the binary flag: 1 if local exists, 0 otherwise\n",
    "    df_rb1[is_local_flag_col] = df_rb1[local_col].apply(\n",
    "        lambda x: isinstance(x, str) and x.strip() != \"\"\n",
    "    ).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca12510c4e588a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:35:18.971730Z",
     "start_time": "2025-09-22T13:29:38.624883Z"
    }
   },
   "outputs": [],
   "source": [
    "from asodesigner.features.cai import calc_CAI\n",
    "\n",
    "# weights_list, weights_flat = calc_CAI_weight(reference_seqs)\n",
    "\n",
    "for flank in CDS_WINDOWS:\n",
    "    local_col = f\"local_coding_region_around_ASO_{flank}\"\n",
    "    CAI_col   = f\"CAI_score_{flank}_CDS\"\n",
    "    df_rb1[CAI_col] = (\n",
    "        df_rb1[local_col].astype(str).apply(lambda s: calc_CAI(s, weights_flat))\n",
    "    )\n",
    "    df_tp53bp1[CAI_col] = (\n",
    "        df_tp53bp1[local_col].astype(str).apply(lambda s: calc_CAI(s, weights_flat))\n",
    "    )\n",
    "df_rb1[\"CAI_score_global_CDS\"] = (\n",
    "    df_rb1[\"cds_sequence\"].astype(str).apply(lambda s: calc_CAI(s, weights_flat))\n",
    ")\n",
    "df_tp53bp1[\"CAI_score_global_CDS\"] = (\n",
    "    df_tp53bp1[\"cds_sequence\"].astype(str).apply(lambda s: calc_CAI(s, weights_flat))\n",
    ")\n",
    "\n",
    "\n",
    "CAI_list = [f\"CAI_score_{flank}_CDS\" for flank in CDS_WINDOWS] + [\"CAI_score_global_CDS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af774898fc08d82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:36:00.668857Z",
     "start_time": "2025-09-22T13:36:00.301649Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rb1_bak = df_rb1.copy()\n",
    "df_tp53bp1_bak = df_tp53bp1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194ca823d9d834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:41:35.704573Z",
     "start_time": "2025-09-22T13:41:35.676567Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tp53bp1 = df_tp53bp1_bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ff092b6b247fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:46:55.699895Z",
     "start_time": "2025-09-22T13:45:51.798531Z"
    }
   },
   "outputs": [],
   "source": [
    "SENSE_START = 'sense_start'\n",
    "SENSE_START_FROM_END = 'sense_start_from_end'\n",
    "SENSE_LENGTH = 'sense_length'\n",
    "SENSE_TYPE = 'sense_type'\n",
    "SENSE_EXON = 'sense_exon'\n",
    "SENSE_INTRON = 'sense_intron'\n",
    "SENSE_UTR = 'sense_utr'\n",
    "\n",
    "for index, row in df_tp53bp1.iterrows():\n",
    "    gene_name = row[CANONICAL_GENE]\n",
    "    locus_info = gene_to_data[gene_name]\n",
    "    pre_mrna = locus_info.full_mrna\n",
    "    antisense = row[SEQUENCE]\n",
    "    idx = row[SENSE_START]\n",
    "    df_tp53bp1.at[index, SENSE_START_FROM_END] = np.abs(\n",
    "        locus_info.exon_indices[-1][1] - locus_info.cds_start - idx\n",
    "    )\n",
    "    if idx != -1:\n",
    "        genome_corrected_index = idx + locus_info.cds_start\n",
    "        found = False\n",
    "        for exon_indices in locus_info.exon_indices:\n",
    "            # print(exon[0], exon[1])\n",
    "            if exon_indices[0] <= genome_corrected_index <= exon_indices[1]:\n",
    "                df_tp53bp1.at[index, SENSE_TYPE] = 'exon'\n",
    "                df_tp53bp1.at[index, SENSE_EXON] = 1\n",
    "                found = True\n",
    "                break\n",
    "        for intron_indices in locus_info.intron_indices:\n",
    "            # print(exon[0], exon[1])\n",
    "            if intron_indices[0] <= genome_corrected_index <= intron_indices[1]:\n",
    "                df_tp53bp1.at[index, SENSE_TYPE] = 'intron'\n",
    "                df_tp53bp1.at[index, SENSE_INTRON] = 1\n",
    "                found = True\n",
    "                break\n",
    "        for i, utr_indices in enumerate(locus_info.utr_indices):\n",
    "                if utr_indices[0] <= genome_corrected_index <= utr_indices[1]:\n",
    "                    df_tp53bp1.at[index, SENSE_TYPE] = 'utr'\n",
    "                    df_tp53bp1.at[index, SENSE_UTR] = 1\n",
    "\n",
    "                    found = True\n",
    "                    break\n",
    "    if not found:\n",
    "        df_tp53bp1.loc[index, SENSE_TYPE] = 'intron'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799be5f5333f47c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:53:37.391802Z",
     "start_time": "2025-09-22T13:48:52.306553Z"
    }
   },
   "outputs": [],
   "source": [
    "SENSE_START = 'sense_start'\n",
    "SENSE_START_FROM_END = 'sense_start_from_end'\n",
    "SENSE_LENGTH = 'sense_length'\n",
    "SENSE_TYPE = 'sense_type'\n",
    "SENSE_EXON = 'sense_exon'\n",
    "SENSE_INTRON = 'sense_intron'\n",
    "SENSE_UTR = 'sense_utr'\n",
    "\n",
    "for index, row in df_rb1.iterrows():\n",
    "    gene_name = row[CANONICAL_GENE]\n",
    "    locus_info = gene_to_data[gene_name]\n",
    "    pre_mrna = locus_info.full_mrna\n",
    "    antisense = row[SEQUENCE]\n",
    "    idx = row[SENSE_START]\n",
    "    df_rb1.at[index, SENSE_START_FROM_END] = np.abs(\n",
    "        locus_info.exon_indices[-1][1] - locus_info.cds_start - idx\n",
    "    )\n",
    "    if idx != -1:\n",
    "        genome_corrected_index = idx + locus_info.cds_start\n",
    "        found = False\n",
    "        for exon_indices in locus_info.exon_indices:\n",
    "            # print(exon[0], exon[1])\n",
    "            if exon_indices[0] <= genome_corrected_index <= exon_indices[1]:\n",
    "                df_rb1.at[index, SENSE_TYPE] = 'exon'\n",
    "                df_rb1.at[index, SENSE_EXON] = 1\n",
    "                found = True\n",
    "                break\n",
    "        for intron_indices in locus_info.intron_indices:\n",
    "            # print(exon[0], exon[1])\n",
    "            if intron_indices[0] <= genome_corrected_index <= intron_indices[1]:\n",
    "                df_rb1.at[index, SENSE_TYPE] = 'intron'\n",
    "                df_rb1.at[index, SENSE_INTRON] = 1\n",
    "                found = True\n",
    "                break\n",
    "        for i, utr_indices in enumerate(locus_info.utr_indices):\n",
    "                if utr_indices[0] <= genome_corrected_index <= utr_indices[1]:\n",
    "                    df_rb1.at[index, SENSE_TYPE] = 'utr'\n",
    "                    df_rb1.at[index, SENSE_UTR] = 1\n",
    "\n",
    "                    found = True\n",
    "                    break\n",
    "    if not found:\n",
    "        df_rb1.loc[index, SENSE_TYPE] = 'intron'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645d3b38e713b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T13:59:46.316387Z",
     "start_time": "2025-09-22T13:59:46.178179Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tp53bp1_scores = model.predict(df_tp53bp1[selected_features])\n",
    "df_rb1_scores = model.predict(df_rb1[selected_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f88f0a0d80af4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:12:20.932213Z",
     "start_time": "2025-09-22T14:00:05.847637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming you already have get_antisense(seq: str) -> str defined\n",
    "# get_antisense, for some reason numba doesn't work well\n",
    "tbl = str.maketrans(\"ACGTUacgtuNn\", \"TGCAAtgcaaNn\")\n",
    "\n",
    "df_tp53bp1[\"score\"] = df_tp53bp1_scores\n",
    "df_rb1[\"score\"] = df_rb1_scores\n",
    "\n",
    "df_tp53bp1[\"sense\"] = df_tp53bp1[SEQUENCE].astype(str).str.translate(tbl).str[::-1]\n",
    "(\n",
    "    df_tp53bp1.assign(score=df_tp53bp1_scores)\n",
    "    .sort_values(\"score\", ascending=False)  # sort by score\n",
    "    .to_csv(\"df_tp53bp1_scores_model2.csv\", index=False)\n",
    ")\n",
    "\n",
    "df_rb1[\"sense\"] = df_rb1[SEQUENCE].astype(str).str.translate(tbl).str[::-1]\n",
    "(\n",
    "    df_rb1.assign(score=df_rb1_scores)\n",
    "    .sort_values(\"score\", ascending=False)  # sort by score\n",
    "    .to_csv(\"df_rb1_scores_model2.csv\", index=False)\n",
    ")\n",
    "\n",
    "df_tp53bp1_sorted = df_tp53bp1.sort_values('score', ascending=False)\n",
    "df_rb1_sorted = df_rb1.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915130879c6995fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:13:16.055607Z",
     "start_time": "2025-09-22T14:13:16.003823Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tp53bp1_sorted.insert(0, \"row_number\", range(1, len(df_tp53bp1_sorted) + 1))\n",
    "df_rb1_sorted.insert(0, \"row_number\", range(1, len(df_rb1_sorted) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09f0a292357b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:15:33.191283Z",
     "start_time": "2025-09-22T14:15:33.154954Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install requests\n",
    "import math, time, threading, urllib.parse, requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "UA = {\"User-Agent\": \"python-requests gggenome/greedy\"}\n",
    "\n",
    "\n",
    "def _ggg_hits_leq_json(seq, k, db=\"hg38\", timeout=60, retries=2):\n",
    "    \"\"\"Count hits with <=k mismatches via GGGenome JSON; fallback to CSV if needed.\"\"\"\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    q = urllib.parse.quote(s)\n",
    "    url_json = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.json\"\n",
    "    url_csv = f\"https://gggenome.dbcls.jp/{db}/{k}/nogap/{q}.csv?download\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url_json, headers=UA, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            try:\n",
    "                data = r.json()\n",
    "            except ValueError:\n",
    "                raise RuntimeError(\"JSON parse failed\")\n",
    "            if isinstance(data, list):\n",
    "                return len(data)\n",
    "            if isinstance(data, dict):\n",
    "                if \"results\" in data and isinstance(data[\"results\"], list): return len(data[\"results\"])\n",
    "                if \"hits\" in data and isinstance(data[\"hits\"], list):       return len(data[\"hits\"])\n",
    "                return sum(len(v) for v in data.values() if isinstance(v, list))\n",
    "            return 10000\n",
    "        except Exception:\n",
    "            # greedy CSV fallback\n",
    "            try:\n",
    "                r2 = requests.get(url_csv, headers=UA, timeout=timeout)\n",
    "                r2.raise_for_status()\n",
    "                return sum(1 for ln in r2.text.splitlines() if ln and not ln.startswith(\"#\"))\n",
    "            except Exception:\n",
    "                if attempt < retries:\n",
    "                    continue\n",
    "                return 10000\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _d123_for_sequence(seq, db=\"hg38\"):\n",
    "    s = str(seq).upper().replace(\"U\", \"T\")\n",
    "    if not s:\n",
    "        return (s, 0, 0, 0)\n",
    "    L = len(s)\n",
    "    k_allowed = max(0, math.floor(0.25 * L))  # GGGenome cap\n",
    "    k0 = _ggg_hits_leq_json(s, 0, db=db)\n",
    "    k1 = _ggg_hits_leq_json(s, 1, db=db) if k_allowed >= 1 else 0\n",
    "    # k2 = _ggg_hits_leq_json(s, 2, db=db) if k_allowed >= 2 else 0\n",
    "    # k3 = _ggg_hits_leq_json(s, 3, db=db) if k_allowed >= 3 else 0\n",
    "    d1 = max(0, k1 - k0)\n",
    "    # d2 = max(0, k2 - k1)\n",
    "    # d3 = max(0, k3 - k2)\n",
    "    return (s, d1, 0, 0, k0)\n",
    "\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def add_gggenome_d123(main_df, seq_col=\"SEQUENCE\", db=\"hg38\", *, max_workers=32, print_every=10):\n",
    "    seqs = (main_df[seq_col].astype(str).str.upper().str.replace(\"U\", \"T\", regex=False))\n",
    "    uniq = seqs.dropna().unique().tolist()\n",
    "    N = len(uniq)\n",
    "    print(f\"[GGG] Unique sequences: {N} | db={db} | workers={max_workers}\")\n",
    "\n",
    "    global cache\n",
    "    cache = {}\n",
    "    lock = threading.Lock()\n",
    "    t0 = time.perf_counter()\n",
    "    errs = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = {ex.submit(_d123_for_sequence, s, db): s for s in uniq}\n",
    "        done = 0\n",
    "        for fut in as_completed(futs):\n",
    "            s = futs[fut]\n",
    "            try:\n",
    "                s_key, d1, d2, d3, d0 = fut.result()\n",
    "            except Exception:\n",
    "                d0 = d1 = d2 = d3 = 0\n",
    "                with lock:\n",
    "                    errs += 1\n",
    "            with lock:\n",
    "                cache[s] = (s, d1, d2, d3, d0)\n",
    "                done += 1\n",
    "                if (done == 1) or (done % print_every == 0) or (done == N):\n",
    "                    elapsed = time.perf_counter() - t0\n",
    "                    rps = done / elapsed if elapsed > 0 else 0.0\n",
    "                    print(f\"[GGG] {done}/{N} cached | ~{rps:.1f} seq/s | errors={errs}\")\n",
    "\n",
    "    main_df[\"ggg_d1\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[1])\n",
    "    main_df[\"ggg_d0\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[4])\n",
    "    # main_df[\"ggg_d2\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[2])\n",
    "    # main_df[\"ggg_d3\"] = seqs.map(lambda s: cache.get(s, (s, 0, 0, 0, 0))[3])\n",
    "\n",
    "    print(f\"[GGG] Finished in {time.perf_counter() - t0:.1f}s. Added columns: ggg_d1, ggg_d2, ggg_d3\")\n",
    "    return main_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749aaa1edf0d643c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:27:03.899793Z",
     "start_time": "2025-09-22T14:15:41.961511Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- usage ---\n",
    "# main_df = main_df[main_df[SENSE_START] != -1]\n",
    "result = add_gggenome_d123(df_tp53bp1_sorted[:150], seq_col='sense', db=\"hg38\", max_workers=1, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e81ebe691bffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:34:40.919114Z",
     "start_time": "2025-09-22T14:34:40.881371Z"
    }
   },
   "outputs": [],
   "source": [
    "result[['row_number', SEQUENCE, 'sense_start', 'ggg_d0', 'ggg_d1', 'sense_avg_accessibility', 'on_target_fold_openness_normalized40_15', 'at_skew', 'gc_content', 'sense_utr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149462cd8aa776f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T15:09:16.708697Z",
     "start_time": "2025-09-22T14:37:57.438226Z"
    }
   },
   "outputs": [],
   "source": [
    "result_rb1 = add_gggenome_d123(df_rb1_sorted[:150], seq_col='sense', db=\"hg38\", max_workers=1, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba8ee660b979a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17e3106c7dcf24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T15:23:06.491289Z",
     "start_time": "2025-09-22T15:23:06.439018Z"
    }
   },
   "outputs": [],
   "source": [
    "tresult_rb1[['row_number', SEQUENCE, 'sense_start', 'ggg_d0', 'ggg_d1', 'sense_avg_accessibility', 'on_target_fold_openness_normalized40_15', 'at_skew', 'gc_content', 'sense_utr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7dfecab1deae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
